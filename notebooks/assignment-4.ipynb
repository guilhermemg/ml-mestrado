{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descrição de Atividade\n",
    "\n",
    "Nessa atividade você irá usar seus conhecimentos sobre classificação para prever quais candidatos à Câmara de Deputados foram eleitos nas eleições de 2014. De forma específica:\n",
    "\n",
    " 1. Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador? Como você poderia tratar isso? (1 pt.)\n",
    " 2. Treine: um modelo de regressão logística, KNN, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.  (2 pts.)\n",
    "Reporte Precision, Recall e AUC-Precision&Recall no treino e validação. Há uma grande diferença de desempenho no treino/validação? Como você avalia os resultados? Justifique sua resposta. (2 pt.)\n",
    " 3. Interprete as saídas dos modelos. Quais atributos parecem ser mais importantes de acordo com cada modelo?  (2 pts.)\n",
    " 4. Envie seus melhores modelos à competição do Kaggle. Faça pelo menos uma submissão. Sugestões para melhorar o modelo: (2 pts.)\n",
    " 5. Experimente outros modelos (e.g. SVM, RandomForests e GradientBoosting).\n",
    " 6. Experimente outras estratégias de ensembles (e.g. Stacking).\n",
    " 7. Experimente balancear as classes,  caso estejam desbalanceadas.\n",
    "\n",
    "Os dados estão neste link: https://www.kaggle.com/c/ufcg-cdp-20182-lab3/data. Links para um site externo\n",
    "\n",
    "Para a entrega envie o link no GitHub com o notebook usado para resolver o Lab.\n",
    "\n",
    "\n",
    "### Descrição dos dados:\n",
    "\n",
    "Os dados utilizados correspondem aos das eleições de Deputado Federal nos anos de 2006, 2010 e 2014. Estão dividos nas seguintes colunas:\n",
    "\n",
    "* **ano**: Ano da eleição;\n",
    "* **sequencial_candidato**: O identificador do candidato. Corresponde à coluna Id do arquivo de submissão;\n",
    "* **nome**: Nome do candidato;\n",
    "* **uf**: Sigla do estado do candidato;\n",
    "* **partido**: Partido do candidato;\n",
    "* **quantidade_doacoes**: Número de doações que um candidato recebeu;\n",
    "* **quantidade_doadores**: Numero de doadores que um candidato teve;\n",
    "* **total_receita**: Total de receita de um candidato;\n",
    "* **media_receita**: Média da receita de um candidato;\n",
    "* **recursos_de_outros_candidatos.comites**: Total de receita proveniente de outros candidatos e comitês;\n",
    "* **recursos_de_pessoas_fisicas**: Total de receita proveniente de pessoas físicas;\n",
    "* **recursos_de_pessoas_juridicas**: Total de receita proveniente de pessoas juridicas;\n",
    "* **recursos_proprios**:Total de receita proveniente dos próprios candidatos;\n",
    "* **recursos_de_partido_politico**: Total de receita proveniente do partido do candidato;\n",
    "* **quantidade_despesas**: Número de despesas que um candidato teve;\n",
    "* **quantidade_fornecedores**: Número de fornecedores que um candidato teve;\n",
    "* **total_despesa**: Total de depesa de um candidato;\n",
    "* **media_despesa**: Média da despesa de um candidato;\n",
    "* **cargo**: Cargo ao qual o candidato está concorrendo;\n",
    "* **sexo**: Sexo do candidato;\n",
    "* **grau**: Grau de escolaridade do candidato;\n",
    "* **estado_civil**: Estado civil do candidato;\n",
    "* **ocupacao**: Ocupação do candidato;\n",
    "* **situacao**: Situação final do candidato. Corresponde à coluna **Predict** do arquivo de submissão;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, auc\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_validate, cross_val_predict\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "sns.set(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/assignment_4/train.csv')\n",
    "test_df = pd.read_csv('../data/assignment_4/test.csv')\n",
    "\n",
    "data = pd.concat([train_df, test_df], sort=False)\n",
    "\n",
    "data.set_index('sequencial_candidato', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['nome'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = QuantileTransformer(random_state=2, output_distribution='normal')\n",
    "\n",
    "skewed_features = ['quantidade_doacoes', 'quantidade_doadores', 'total_receita',\n",
    "       'media_receita', 'recursos_de_outros_candidatos.comites',\n",
    "       'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "       'recursos_proprios', 'recursos_de_partido_politico',\n",
    "       'quantidade_despesas', 'quantidade_fornecedores', 'total_despesa',\n",
    "       'media_despesa']\n",
    "\n",
    "data[skewed_features] = qt.fit_transform(X=data[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_nums = {\"grau\" : {\"LÊ E ESCREVE\": 1, \n",
    "                       \"ENSINO FUNDAMENTAL INCOMPLETO\":2, \n",
    "                       \"ENSINO FUNDAMENTAL COMPLETO\":3, \n",
    "                       \"ENSINO MÉDIO INCOMPLETO\":4,\n",
    "                       \"ENSINO MÉDIO COMPLETO\":5,\n",
    "                       \"SUPERIOR INCOMPLETO\":6,\n",
    "                       \"SUPERIOR COMPLETO\": 7}}\n",
    "\n",
    "data.replace(cleanup_nums, inplace=True)\n",
    "data[\"grau\"] = pd.to_numeric(data[\"grau\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12214, 258)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feats = [col for col in data.columns if not np.issubdtype(data[str(col)].dtype, np.number) and col not in ['nome', 'situacao']]\n",
    "\n",
    "data = pd.get_dummies(data, columns=categorical_feats)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7622, 259)\n",
      "(4592, 259)\n"
     ]
    }
   ],
   "source": [
    "data['situacao_dummy'] = data['situacao'].map({'eleito': 1, 'nao_eleito': 0})\n",
    "\n",
    "train = data[(data.ano == 2006) | (data.ano == 2010)]\n",
    "test = data[data.ano == 2014]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Class Imbalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2542965c50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='situacao', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de candidatos Eleitos: 1026\n",
      "Número de candidatos Não-Eleitos: 6596\n",
      "Total de candidatos: 7622\n",
      "\n",
      "Proporção de candidatos eleitos: 13.46%\n",
      "Proporção de candidatos não-eleitos: 86.54%\n"
     ]
    }
   ],
   "source": [
    "num_elected_candidates = train.situacao[train.situacao == 'eleito'].count()\n",
    "num_not_elected_candidates = train.situacao[train.situacao == 'nao_eleito'].count()\n",
    "total_candidates = train.shape[0]\n",
    "\n",
    "print(\"Número de candidatos Eleitos: {}\".format(num_elected_candidates))\n",
    "print(\"Número de candidatos Não-Eleitos: {}\".format(num_not_elected_candidates))\n",
    "print(\"Total de candidatos: {}\\n\".format(total_candidates))\n",
    "\n",
    "print(\"Proporção de candidatos eleitos: {:2.2%}\".format((num_elected_candidates/total_candidates)))\n",
    "print(\"Proporção de candidatos não-eleitos: {:2.2%}\".format((num_not_elected_candidates/total_candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável alvo **situacao** é bastante _desbalanceada_, em uma proporção de aproximadamente 1 eleito para cada 6 não-eleitos. Precisamente 13.46% dos candidatos foram eleitos, enquanto 86.54% não foram eleitos.\n",
    "\n",
    "Esse desbalanceamento pode causar alguns efeitos colaterais na classificação feita pelo modelo preditor, tais como overfitting do modelo em relação à classe majoritária, o que prejudica a acurácia da predição, podendo causar até mesmo a interpretação incorreta dos resultados se o desbalanceamento não for endereçado corretamente.\n",
    "\n",
    "Existem algumas práticas que podemos adotar para corrigir e lidar com esse desbalanceamento, a saber:\n",
    "\n",
    "* Coleta de mais dados, que poderia rebalancear as classes, a depender da natureza do problema;\n",
    "* Mudar a forma de amostragem do dataset, a qual pode estar gerando uma amostra desbalanceada, contudo o dataset não está desbalanceado;\n",
    "* Usar alguma forma de gerar dados sintéticos como Synthetic Minority Over-sampling Technique [SMOTE](https://imbalanced-learn.org/en/stable/over_sampling.html#cbhk2002) e Adaptive Synthetic [ADASYN](https://imbalanced-learn.org/en/stable/over_sampling.html#hbgl2008);\n",
    "* Incorporar algum modelo que tem uma forma de penalização para compensar o desbalanceamento de classes a exemplo de penalized-LDA e penalized-SVM.\n",
    "\n",
    "\n",
    "Para essa atividade nós usaremos a técnica de geração de dados sintéticos SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train SMOTE: [(0.0, 6596), (1.0, 6596)]\n",
      "Test.shape: (4592, 257)\n"
     ]
    }
   ],
   "source": [
    "train.drop(['situacao'], axis=1, inplace=True)\n",
    "test.drop(['situacao', 'situacao_dummy'], axis=1, inplace=True)\n",
    "\n",
    "X = train.loc[:, train.columns != 'situacao_dummy']\n",
    "y = train.situacao_dummy\n",
    "\n",
    "X_train, y_train = SMOTE().fit_resample(X, y)\n",
    "print(\"Train SMOTE: {}\".format(sorted(Counter(y_train).items())))\n",
    "\n",
    "#X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "\n",
    "X_test = test\n",
    "print(\"Test.shape: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "#print(\"Train: {}\".format(X_train.shape, y_train.shape))\n",
    "#print(\"Test: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelsPaths(Enum):\n",
    "    KNR_PATH = 'assignment4-models/knr.p'\n",
    "    LR_PATH = 'assignment4-models/lr.p'\n",
    "    DT_PATH = 'assignment4-models/dt.p'\n",
    "    ADA_PATH = 'assignment4-models/ada.p'\n",
    "    RF_PATH = 'assignment4-models/rf.p'\n",
    "    ET_PATH = 'assignment4-models/et.p'\n",
    "    SVC_PATH = 'assignment4-models/svc.p'\n",
    "    LGBM_PATH = 'assignment4-models/lgbm.p'\n",
    "    CAT_PATH = 'assignment4-models/cat.p'\n",
    "    XGB_PATH = 'assignment4-models/xgb.p'\n",
    "\n",
    "class ModelsNames(Enum):\n",
    "    LR = 'Logistic Regression'\n",
    "    DT = 'Decision Trees'\n",
    "    ET = 'Extra Trees'\n",
    "    RF = 'Random Forest'\n",
    "    ADA = 'AdaBoost'\n",
    "    SVC = 'Support Vector Machine'\n",
    "    LGBM = 'LGBM'\n",
    "    CAT = 'CatBoost'\n",
    "    XGB = 'XGBoost'\n",
    "    KNR = 'KNR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trained_model(self, path):\n",
    "    pickle.dump(self.model, open(path.value, 'wb'))\n",
    "\n",
    "def load_trained_model(self, path):\n",
    "    return pickle.load(open(path.value, 'rb'))\n",
    "\n",
    "def _get_top_10_features_and_imps(self, f_names, f_imps):\n",
    "    aux = [(f_name, f_imp) for f_idx_a, f_name in f_names for f_idx_b, f_imp in f_imps if f_idx_a == f_idx_b]\n",
    "    aux.sort(key=lambda tup: -tup[1]) # sort by feature_importance, descending order\n",
    "\n",
    "    top_10_features = aux[:10]\n",
    "    features_names = [x for x,_ in top_10_features]\n",
    "    features_imps = [y for _,y in top_10_features]\n",
    "\n",
    "    return (features_names, features_imps)\n",
    "\n",
    "def _get_feat_names_and_imps_1(self):\n",
    "    f_names = [(f_idx, f_name) for f_idx, f_name in enumerate(train.columns)]\n",
    "    f_imps = [(f_idx, f_imp) for f_idx, f_imp in enumerate(self.model.feature_importances_)]\n",
    "\n",
    "    return _get_top_10_features_and_imps(f_names, f_imps)\n",
    "\n",
    "def _get_feat_names_and_imps_2(self):\n",
    "    imps = (np.std(X_train, 0) * self.model.coef_)[0]\n",
    "\n",
    "    f_names = [(f_idx, f_name) for f_idx, f_name in enumerate(train.columns)]\n",
    "    f_imps = [(f_idx, f_imp) for f_idx, f_imp in enumerate(imps)]\n",
    "\n",
    "    return _get_top_10_features_and_imps(f_names, f_imps)\n",
    "\n",
    "\n",
    "def _plot_graph(self, model_name, features_names, features_imps):\n",
    "    # Scatter plot \n",
    "    trace = go.Scatter(\n",
    "        y = features_imps,\n",
    "        x = features_names,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            sizemode = 'diameter',\n",
    "            sizeref = 1,\n",
    "            size = 25,\n",
    "            color = features_imps,\n",
    "            colorscale='Portland',\n",
    "            showscale=True\n",
    "        ),\n",
    "        text = features_names\n",
    "    )\n",
    "    data = [trace]\n",
    "\n",
    "    layout= go.Layout(\n",
    "        autosize= True,\n",
    "        title= '{} Feature Importance'.format(model_name.value),\n",
    "        hovermode= 'closest',\n",
    "        yaxis=dict(\n",
    "            title= 'Feature Importance',\n",
    "            ticklen= 5,\n",
    "            gridwidth= 2\n",
    "        ),\n",
    "        showlegend= False\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig, filename='scatter2010')\n",
    "\n",
    "\n",
    "def plot_feature_importances(self, model_name):\n",
    "    feature_names, feature_imps = None,None\n",
    "\n",
    "    if model_name in [ModelsNames.DT, ModelsNames.ET, ModelsNames.RF, ModelsNames.ADA]:\n",
    "        feature_names, feature_imps = _get_feat_names_and_imps_1()\n",
    "    elif model_name in [ModelsNames.LR]:\n",
    "        feature_names, feature_imps = _get_feat_names_and_imps_2()\n",
    "\n",
    "    _plot_graph(model_name, feature_names, feature_imps)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class GenericModel(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.nfolds = 10\n",
    "        self.seed = 42\n",
    "    \n",
    "    def report_cross_validation_results(self):\n",
    "        print('(Cross-)Validation set evaluation')\n",
    "\n",
    "        report_val = {}\n",
    "        scoring = ['precision','recall','f1','accuracy', 'roc_auc']\n",
    "        for sc in scoring:\n",
    "            cv = StratifiedKFold(shuffle=True, random_state=self.seed, n_splits=self.nfolds)\n",
    "            report_val[sc] = cross_val_score(self.model, X_train, y_train, cv=cv, scoring=sc, n_jobs=-1).mean()\n",
    "\n",
    "        for key, val in report_val.items():\n",
    "            print('{} score - validation set: {:.4}'.format(key.capitalize(), val))\n",
    "\n",
    "\n",
    "    def report_results_with_test_set(self):\n",
    "        print('----------------------')\n",
    "        print('Test set evaluation:')\n",
    "\n",
    "        y_pred_test = self.model.predict(X_test)\n",
    "\n",
    "        report_test = {}\n",
    "        report_test['precision'] = precision_score(y_test, y_pred_test)\n",
    "        report_test['recall'] = recall_score(y_test, y_pred_test)\n",
    "        report_test['f1'] = f1_score(y_test, y_pred_test)\n",
    "        report_test['accuracy'] = accuracy_score(y_test, y_pred_test)\n",
    "        report_test['roc_auc'] = roc_auc_score(y_test, y_pred_test)\n",
    "        report_test['auc'] = auc_score(y_test, y_pred_test)\n",
    "\n",
    "        for key, val in report_test.items():\n",
    "            print('{} score - test set: {:.4}'.format(key.capitalize(), val))\n",
    "\n",
    "        print('\\nConfusion Matrix:')\n",
    "        print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Definitions\n",
    "\n",
    "Abaixo definimos alguns wrappers para os modelos que vamos utilizar. Créditos para [**eliotbarr**](https://www.kaggle.com/eliotbarr/stacking-test-sklearn-xgboost-catboost-lightgbm/code) e [**arthurtok**](https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python) no Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = X_train.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "\n",
    "NFOLDS = 3\n",
    "SEED = 42\n",
    "\n",
    "class GenericWrapper(object):\n",
    "    def __init__(self, clf, params=None):\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.clf.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return self.clf.predict_proba(x)[:,1]\n",
    "\n",
    "class SklearnWrapper_1(GenericWrapper):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        super().__init__(clf, params)\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        super().train(X_train, y_train)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super().predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return super().predict_proba(x)\n",
    "    \n",
    "class SklearnWrapper_2(GenericWrapper):\n",
    "    def __init__(self, clf, params=None):\n",
    "        super().__init__(clf, params)\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        super().train(X_train, y_train)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super().predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return super().predict_proba(x)\n",
    "    \n",
    "    \n",
    "class CatboostWrapper(GenericWrapper):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_seed'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        super().train(X_train, y_train)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super().predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return super().predict_proba(x)\n",
    "        \n",
    "class LightGBMWrapper(GenericWrapper):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['feature_fraction_seed'] = seed\n",
    "        params['bagging_seed'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        super().train(X_train, y_train)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super().predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return super().predict_proba(x)\n",
    "\n",
    "\n",
    "class XgbWrapper(GenericWrapper):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['seed'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        super().train(X_train, y_train)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super().predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return super().predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_proba = np.zeros((ntest,))\n",
    "    \n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "    oof_test_skf_proba = np.empty((NFOLDS, ntest))\n",
    "    \n",
    "    kf = StratifiedKFold(shuffle=True, random_state=SEED, n_splits=NFOLDS)\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "        x_tr = X_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = X_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(X_test)\n",
    "        oof_test_skf_proba[i, :] = clf.predict_proba(X_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    oof_test_proba[:] = oof_test_skf_proba.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1), oof_test_proba.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    'solver': 'liblinear'\n",
    "}\n",
    "\n",
    "knr_params = {\n",
    "    'n_neighbors': 3\n",
    "}\n",
    "\n",
    "dt_params = {\n",
    "}\n",
    "\n",
    "ada_params = {\n",
    "    'learning_rate': 0.01\n",
    "}\n",
    "\n",
    "et_params = {\n",
    "    #'n_jobs': 16,\n",
    "    #'n_estimators': 200,\n",
    "    #'max_features': 0.5,\n",
    "    #'max_depth': 12,\n",
    "    #'min_samples_leaf': 2\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    #'n_jobs': 16,\n",
    "    #'n_estimators': 200,\n",
    "    #'max_features': 0.2,\n",
    "    #'max_depth': 12,\n",
    "    #'min_samples_leaf': 2\n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    'probability': True,\n",
    "    'gamma' : 'auto'\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    #'colsample_bytree': 0.7,\n",
    "    'silent': 1,\n",
    "    #'subsample': 0.7,\n",
    "    'learning_rate': 0.1,\n",
    "    #'objective': 'binary:logistic',\n",
    "    #'max_depth': 4,\n",
    "    #'num_parallel_tree': 1,\n",
    "    #'min_child_weight': 1,\n",
    "    'nrounds': 200\n",
    "}\n",
    "\n",
    "catboost_params = {\n",
    "    'iterations': 200,\n",
    "    'learning_rate': 0.5,\n",
    "    'depth': 3,\n",
    "    #'l2_leaf_reg': 40,\n",
    "    #'bootstrap_type': 'Bernoulli',\n",
    "    #'subsample': 0.7,\n",
    "    #'scale_pos_weight': 5,\n",
    "    'eval_metric': 'AUC',\n",
    "    #'od_type': 'Iter',\n",
    "    'allow_writing_files': False,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "lightgbm_params = {\n",
    "    #'n_estimators':200,\n",
    "    'learning_rate':0.1,\n",
    "    #'num_leaves':123,\n",
    "    #'colsample_bytree':0.8,\n",
    "    #'subsample':0.9,\n",
    "    #'max_depth':15,\n",
    "    #'reg_alpha':0.1,\n",
    "    #'reg_lambda':0.1,\n",
    "    #'min_split_gain':0.01,\n",
    "    #'min_child_weight':2  ,\n",
    "    'silent': 1,\n",
    "    'random_state': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_KNN (K-Nearest Neighbors)_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knr = KNeighborsClassifier(n_neighbors = 3).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(knr)\n",
    "report_results_with_test_set(knr)\n",
    "save_trained_model(knr, ModelsPaths.KNR_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Logistic Regression_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(lr)\n",
    "report_results_with_test_set(lr)\n",
    "save_trained_model(lr, ModelsPaths.LR_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _**Decision Tree Classifier**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state = 42).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(dt)\n",
    "report_results_with_test_set(dt)\n",
    "save_trained_model(dt, ModelsPaths.DT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Adaboost Ensemble_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(random_state=42, learning_rate=0.01).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(ada)\n",
    "report_results_with_test_set(ada)\n",
    "save_trained_model(ada, ModelsPaths.ADA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Random Forest Classifier_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 42).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(rf)\n",
    "report_results_with_test_set(rf)\n",
    "save_trained_model(rf, ModelsPaths.RF_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Extra Trees Classifier_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(et)\n",
    "report_results_with_test_set(et)\n",
    "save_trained_model(et, ModelsPaths.ET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Support Vector Classifier_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(random_state=42, probability=True).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(svc)\n",
    "report_results_with_test_set(svc)\n",
    "save_trained_model(svc, ModelsPaths.SVC_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Gradient Boosting Classifier - LightGBM_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(silent=1, random_state=42, learning_rate=0.1).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(lgbm)\n",
    "report_results_with_test_set(lgbm)\n",
    "save_trained_model(lgbm, ModelsPaths.LGBM_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Gradient Boosting Classifier - CatBoost_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(random_state=42, learning_rate=0.5, allow_writing_files=False, verbose=0, iterations=200, depth=3).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(cat)\n",
    "report_results_with_test_set(cat)\n",
    "save_trained_model(cat, ModelsPaths.CAT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Gradient Boosting Classifier - XGBoost_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.1, silent=1, seed=42).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(xgb)\n",
    "report_results_with_test_set(xgb)\n",
    "save_trained_model(xgb, ModelsPaths.XGB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo listamos as 10 features mais importantes elencadas por diferentes modelos que usamos, após o treinamento destes. Créditos para [**arthurtok**](https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python/notebook) no Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tress, AdaBoost, Random Forest Classifier e Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt   = load_trained_model(ModelsPaths.DT_PATH)\n",
    "ada  = load_trained_model(ModelsPaths.ADA_PATH)\n",
    "rf   = load_trained_model(ModelsPaths.RF_PATH)\n",
    "et   = load_trained_model(ModelsPaths.ET_PATH)\n",
    "\n",
    "models = [(dt, ModelsNames.DT), (ada, ModelsNames.ADA), (rf, ModelsNames.RF), (et, ModelsNames.ET)]\n",
    "\n",
    "for model, model_name in models:\n",
    "    plot_feature_importances(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que esses modelos divergem quanto à principal feature que deve ser considerada para que um candidato seja eleito. Entretanto, podemos ver algumas que se repetem e que eles consideram como tendo maior importância:\n",
    "\n",
    "* total receita\n",
    "* ocupação Deputado (candidatos tentando reeleição)\n",
    "* total despesa\n",
    "* recursos obtidos (pessoas jurídicas, pessoas físicas, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr   = load_trained_model(ModelsPaths.LR_PATH)\n",
    "plot_feature_importances(lr, ModelsNames.LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knr  = load_trained_model(ModelsPaths.KNR_PATH)\n",
    "svc  = load_trained_model(ModelsPaths.SVC_PATH)\n",
    "lgbm = load_trained_model(ModelsPaths.LGBM_PATH)\n",
    "cat  = load_trained_model(ModelsPaths.CAT_PATH)\n",
    "xgb  = load_trained_model(ModelsPaths.XGB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Level Training - Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _**Logistic Regression-based Stacking Classifier**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 258 features per sample; expecting 257",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-343048b7c37f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mxg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXgbWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlr_oof_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_oof_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_oof_test_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_oof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mad_oof_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mad_oof_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mad_oof_test_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_oof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0met_oof_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0met_oof_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0met_oof_test_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_oof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0met\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-83d0b9eeedc4>\u001b[0m in \u001b[0;36mget_oof\u001b[0;34m(clf)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moof_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moof_test_skf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moof_test_skf_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-1fa249dcc13a>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-1fa249dcc13a>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 262\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 258 features per sample; expecting 257"
     ]
    }
   ],
   "source": [
    "lr = SklearnWrapper_1(clf=LogisticRegression, params=lr_params)\n",
    "ad = SklearnWrapper_1(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "et = SklearnWrapper_1(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "rf = SklearnWrapper_1(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "dt = SklearnWrapper_1(clf=DecisionTreeClassifier, seed=SEED, params=dt_params)\n",
    "sv = SklearnWrapper_1(clf=SVC, seed=SEED, params=svc_params)\n",
    "kn = SklearnWrapper_2(clf=KNeighborsClassifier, params=knr_params)\n",
    "lg = LightGBMWrapper(clf = LGBMClassifier, seed = SEED, params = lightgbm_params)\n",
    "cb = CatboostWrapper(clf= CatBoostClassifier, seed = SEED, params=catboost_params)\n",
    "xg = XgbWrapper(clf=XGBClassifier, seed=SEED, params=xgb_params)\n",
    "\n",
    "lr_oof_train, lr_oof_test, lr_oof_test_proba = get_oof(lr)\n",
    "ad_oof_train, ad_oof_test, ad_oof_test_proba = get_oof(ad)\n",
    "et_oof_train, et_oof_test, et_oof_test_proba = get_oof(et)\n",
    "rf_oof_train, rf_oof_test, rf_oof_test_proba = get_oof(rf)\n",
    "dt_oof_train, dt_oof_test, dt_oof_test_proba = get_oof(dt)\n",
    "sv_oof_train, sv_oof_test, sv_oof_test_proba = get_oof(sv)\n",
    "kn_oof_train, kn_oof_test, kn_oof_test_proba = get_oof(kn)\n",
    "lg_oof_train, lg_oof_test, lg_oof_test_proba = get_oof(lg)\n",
    "cb_oof_train, cb_oof_test, cb_oof_test_proba = get_oof(cb)\n",
    "xg_oof_train, xg_oof_test, xg_oof_test_proba = get_oof(xg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Intermediary Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Precision: 0.9033\n",
      "Recall: 0.9591\n",
      "F1: 0.9304\n",
      "Accuracy: 0.9282\n",
      "Roc_auc: 0.9282\n",
      "----------------------\n",
      "Model: AdaBoost\n",
      "Precision: 0.8715\n",
      "Recall: 0.9668\n",
      "F1: 0.9167\n",
      "Accuracy: 0.9121\n",
      "Roc_auc: 0.9121\n",
      "----------------------\n",
      "Model: Extra Trees\n",
      "Precision: 0.9425\n",
      "Recall: 0.9817\n",
      "F1: 0.9617\n",
      "Accuracy: 0.9609\n",
      "Roc_auc: 0.9609\n",
      "----------------------\n",
      "Model: Random Forest\n",
      "Precision: 0.9301\n",
      "Recall: 0.9659\n",
      "F1: 0.9476\n",
      "Accuracy: 0.9466\n",
      "Roc_auc: 0.9466\n",
      "----------------------\n",
      "Model: Decision Trees\n",
      "Precision: 0.9258\n",
      "Recall: 0.9313\n",
      "F1: 0.9286\n",
      "Accuracy: 0.9284\n",
      "Roc_auc: 0.9284\n",
      "----------------------\n",
      "Model: KNR\n",
      "Precision: 0.8759\n",
      "Recall: 0.9983\n",
      "F1: 0.9331\n",
      "Accuracy: 0.9284\n",
      "Roc_auc: 0.9284\n",
      "----------------------\n",
      "Model: Support Vector Machine\n",
      "Precision: 0.8947\n",
      "Recall: 0.9712\n",
      "F1: 0.9314\n",
      "Accuracy: 0.9284\n",
      "Roc_auc: 0.9284\n",
      "----------------------\n",
      "Model: LGBM\n",
      "Precision: 0.9425\n",
      "Recall: 0.97\n",
      "F1: 0.9561\n",
      "Accuracy: 0.9554\n",
      "Roc_auc: 0.9554\n",
      "----------------------\n",
      "Model: CatBoost\n",
      "Precision: 0.9401\n",
      "Recall: 0.9621\n",
      "F1: 0.951\n",
      "Accuracy: 0.9504\n",
      "Roc_auc: 0.9504\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "results = [(ModelsNames.LR, lr_oof_train), (ModelsNames.ADA, ad_oof_train), \n",
    "           (ModelsNames.ET, et_oof_train), (ModelsNames.RF, rf_oof_train), \n",
    "           (ModelsNames.DT, dt_oof_train), (ModelsNames.KNR, kn_oof_train), \n",
    "           (ModelsNames.SVC, sv_oof_train), (ModelsNames.LGBM, lg_oof_train), \n",
    "           (ModelsNames.CAT, cb_oof_train)]\n",
    "\n",
    "\n",
    "for m_name, m_train_result in results:        \n",
    "    print(\"Model: {}\".format(m_name.value))\n",
    "    print(\"Precision: {:.4}\".format(precision_score(y_train, m_train_result)))\n",
    "    print(\"Recall: {:.4}\".format(recall_score(y_train, m_train_result)))\n",
    "    print(\"F1: {:.4}\".format(f1_score(y_train, m_train_result)))\n",
    "    print(\"Accuracy: {:.4}\".format(accuracy_score(y_train, m_train_result)))\n",
    "    print(\"Roc_auc: {:.4}\".format(roc_auc_score(y_train, m_train_result)))\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_stacked_model(model):\n",
    "    scoring = ['precision', 'recall', 'f1', 'accuracy', 'roc_auc']\n",
    "    scores = cross_validate(model, x__train, y__train, cv=3, scoring=scoring)\n",
    "    \n",
    "    print(\"\\nAvaliação de Stacked Model com CV:\")\n",
    "    print(\"Precision: {:.4}\".format(scores['test_precision'].mean()))\n",
    "    print(\"Recall: {:.4}\".format(scores['test_recall'].mean()))\n",
    "    print(\"F1: {:.4}\".format(scores['test_f1'].mean()))\n",
    "    print(\"Accuracy: {:.4}\".format(scores['test_accuracy'].mean()))\n",
    "    print(\"Roc_auc: {:.4}\".format(scores['test_roc_auc'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x__train.shape: (13192, 9)\n",
      "y__train.shape: (13192,)\n",
      "x__test.shape:(4592, 9)\n",
      "\n",
      "Avaliação de Stacked Model com CV:\n",
      "Precision: 0.9488\n",
      "Recall: 0.9623\n",
      "F1: 0.955\n",
      "Accuracy: 0.9553\n",
      "Roc_auc: 0.9767\n"
     ]
    }
   ],
   "source": [
    "x__train = np.concatenate((lr_oof_train, ad_oof_train, et_oof_train, rf_oof_train, dt_oof_train,\n",
    "                          kn_oof_train, sv_oof_train, lg_oof_train, cb_oof_train), axis=1)\n",
    "x__test = np.concatenate((lr_oof_test, ad_oof_test, et_oof_test, rf_oof_test, dt_oof_test,\n",
    "                         kn_oof_test, sv_oof_test, lg_oof_test, cb_oof_test), axis=1)\n",
    "y__train = y_train.copy()\n",
    "\n",
    "print(\"x__train.shape: {}\".format(x__train.shape))\n",
    "print(\"y__train.shape: {}\".format(y__train.shape))\n",
    "print(\"x__test.shape:{}\".format(x__test.shape))\n",
    "\n",
    "scoring = ['precision', 'recall', 'f1', 'accuracy', 'roc_auc']\n",
    "clf = LogisticRegression(solver='liblinear')\n",
    "clf.fit(x__train, y__train)\n",
    "\n",
    "evaluate_stacked_model(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Prediction to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000000135</td>\n",
       "      <td>nao_eleito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000000142</td>\n",
       "      <td>nao_eleito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000000158</td>\n",
       "      <td>eleito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000000161</td>\n",
       "      <td>nao_eleito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000000163</td>\n",
       "      <td>eleito</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   Predicted\n",
       "0  10000000135  nao_eleito\n",
       "1  10000000142  nao_eleito\n",
       "2  10000000158      eleito\n",
       "3  10000000161  nao_eleito\n",
       "4  10000000163      eleito"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_df = pd.DataFrame(X_test)\n",
    "pred = logistic_regression.predict(x__test)\n",
    "stack_df['Predicted'] = pred\n",
    "\n",
    "seq_candidato = stack_df.index\n",
    "\n",
    "stack_df.replace({'Predicted': {0: 'nao_eleito', 1: 'eleito'}}, inplace=True)\n",
    "stack_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "final_df = pd.DataFrame(columns=['Id','Predicted'])\n",
    "final_df['Id'] = seq_candidato\n",
    "final_df['Predicted'] = stack_df['Predicted']\n",
    "\n",
    "final_df.to_csv('../data/assignment_4/second_submission.csv', index=False)\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_models = ['knr','lr','dt','ada','rf','svc','et','lgbm','cat','xgb']\n",
    "\n",
    "stack_df = pd.DataFrame(columns=origin_models + ['oracle'])\n",
    "\n",
    "stack_df['knr'] = knr.predict_proba(X_test)[:,1]\n",
    "stack_df['lr'] = lr.predict_proba(X_test)[:,1]\n",
    "stack_df['dt'] = dt.predict_proba(X_test)[:,1]\n",
    "stack_df['ada'] = ada.predict_proba(X_test)[:,1]\n",
    "stack_df['rf'] = rf.predict_proba(X_test)[:,1]\n",
    "stack_df['svc'] = svc.predict_proba(X_test)[:,1]\n",
    "stack_df['et'] = et.predict_proba(X_test)[:,1]\n",
    "stack_df['lgbm'] = lgbm.predict_proba(X_test)[:,1]\n",
    "stack_df['cat'] = cat.predict_proba(X_test)[:,1]\n",
    "stack_df['xgb'] = xgb.predict_proba(X_test)[:,1]\n",
    "stack_df['oracle'] = y_test\n",
    "\n",
    "stack_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previouslly:\n",
    "\n",
    "* Precision: 0.9481\n",
    "* Recall: 0.9884\n",
    "* F1: 0.9679\n",
    "* Accuracy: 0.9678\n",
    "* Roc_auc: 0.9682\n",
    "\n",
    "After add XGBoostClassifier:\n",
    "\n",
    "* Precision: 0.9658\n",
    "* Recall: 0.9807\n",
    "* F1: 0.9732\n",
    "* Accuracy: 0.9735\n",
    "* Roc_auc: 0.9736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x__train, x__test, y__train, y__test = train_test_split(stack_df[origin_models], stack_df.oracle, test_size=0.2, random_state=42)\n",
    "\n",
    "stack_lr = LogisticRegression(solver='liblinear').fit(x__train, y__train)\n",
    "pred = stack_lr.predict(x__test)\n",
    "\n",
    "print('Precision: {:.4}'.format(precision_score(y__test, pred)))\n",
    "print('Recall: {:.4}'.format(recall_score(y__test, pred)))\n",
    "print('F1: {:.4}'.format(f1_score(y__test, pred)))\n",
    "print('Accuracy: {:.4}'.format(accuracy_score(y__test, pred)))\n",
    "print('Roc_auc: {:.4}'.format(roc_auc_score(y__test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA - Usando Pipelines e GridSearch do Scikit Learn\n",
    "\n",
    "Abaixo nós fazemos alguns pipelines e grid searches com os mesmos algoritmos usados acima com o intuito de checar se os valores obtidos são correspondentes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def rmse_function(y_pred, y_true):\n",
    "    return np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
    "\n",
    "scorer = make_scorer(rmse_function, greater_is_better=False)\n",
    "\n",
    "# Construct some pipelines\n",
    "pipe_lr = Pipeline([('reg', LinearRegression())])\n",
    "pipe_rf = Pipeline([('reg', RandomForestRegressor())])\n",
    "pipe_lasso = Pipeline([('reg', LassoCV())])\n",
    "pipe_ridge = Pipeline([('reg', RidgeCV())])\n",
    "pipe_knn = Pipeline([('reg', KNeighborsRegressor())])\n",
    "pipe_dt = Pipeline([('reg', DecisionTreeRegressor())])\n",
    "pipe_svr = Pipeline([('reg', SVR())])\n",
    "\n",
    "\n",
    "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "grid_params_lr = [{}] \n",
    "\n",
    "grid_params_lasso = [{'reg__alphas' : [[5e-1, 1e-1, 5e-2, 1e-3, 1e-4, 1e-5, 1e-6]],\n",
    "                      'reg__max_iter' : [1e5],\n",
    "                      'reg__random_state' : [2]}]\n",
    "\n",
    "grid_params_ridge = [{'reg__alphas' : [[0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]]}]\n",
    "\n",
    "grid_params_rf = [{}]\n",
    "\n",
    "grid_params_knn = [{'reg__n_neighbors' : [1, 3, 5, 7, 10, 15, 18, 21]}]\n",
    "\n",
    "grid_params_dt = [{'reg__random_state' : [2],\n",
    "                   'reg__max_depth' : [5, 10, 50]}]\n",
    "\n",
    "grid_params_svr = [{'reg__C': [1e0, 1e1, 1e2, 1e3]}]\n",
    "\n",
    "# Construct grid searches\n",
    "jobs = -1\n",
    "\n",
    "gs_lr = GridSearchCV(estimator = pipe_lr,\n",
    "                param_grid = grid_params_lr,\n",
    "                scoring = scorer,\n",
    "                cv = 5) \n",
    "\n",
    "gs_rf = GridSearchCV(estimator = pipe_rf,\n",
    "                param_grid = grid_params_rf,\n",
    "                scoring = scorer,\n",
    "                cv = 5, \n",
    "                n_jobs = jobs)\n",
    "\n",
    "gs_lasso = GridSearchCV(estimator = pipe_lasso,\n",
    "                       param_grid = grid_params_lasso,\n",
    "                       scoring = scorer,\n",
    "                       cv = 5,\n",
    "                       n_jobs = jobs)\n",
    "\n",
    "gs_ridge = GridSearchCV(estimator = pipe_ridge,\n",
    "                       param_grid = grid_params_ridge,\n",
    "                       scoring = scorer,\n",
    "                       cv = 5,\n",
    "                       n_jobs = jobs)\n",
    "\n",
    "gs_knn = GridSearchCV(estimator = pipe_knn,\n",
    "                     param_grid = grid_params_knn,\n",
    "                     scoring = scorer,\n",
    "                     cv = 5,\n",
    "                     n_jobs = jobs)\n",
    "\n",
    "gs_dt = GridSearchCV(estimator = pipe_dt,\n",
    "                    param_grid = grid_params_dt,\n",
    "                    scoring = scorer,\n",
    "                    cv = 5,\n",
    "                    n_jobs = jobs)\n",
    "\n",
    "gs_svr = GridSearchCV(estimator = pipe_svr,\n",
    "                     param_grid = grid_params_svr,\n",
    "                     scoring = scorer,\n",
    "                     cv = 5,\n",
    "                     n_jobs = jobs)\n",
    "\n",
    "# List of pipelines for ease of iteration\n",
    "grids = [gs_lr, gs_rf, gs_ridge, gs_lasso, gs_knn, gs_dt, gs_svr]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "grid_dict = {0: 'Linear Regressor', 1: 'Random Forest Regressor', \n",
    "            2: 'Ridge Regressor', 3: 'Lasso Regressor', \n",
    "            4: 'KNN Regressor', 5: 'Decision Tree Regressor',\n",
    "            6: 'SVR Regressor'}\n",
    "\n",
    "\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_rmse = float(\"inf\")\n",
    "best_reg = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\n",
    "    # Fit grid search\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    \n",
    "    # Best training data accuracy\n",
    "    print('Best RMSE for training set: %.10f' % -gs.best_score_)\n",
    "    \n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_pred))\n",
    "    \n",
    "    # Validation data accuracy of model with best params\n",
    "    print('Test set RMSE for best params: %.10f ' % rmse)\n",
    "    \n",
    "    # Track best (smallest rmse) model\n",
    "    if best_rmse > rmse:\n",
    "        best_rmse = rmse\n",
    "        best_gs = gs\n",
    "        best_reg = idx\n",
    "        \n",
    "print('\\nRegressor with best test set RMSE: ** %s **' % grid_dict[best_reg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "Como se observa acima, o melhor modelo encontrado foi o modelo **Lasso Regressor** em termos de RMSE, com o modelo **Ridge Regressor** bem próximo dele em termos de RMSE.\n",
    "\n",
    "Entretanto os valores de RMSE são distintos dos valores encontrados acima. Isso pode se dever ao ajuste dos parâmetros dos modelos, feitos durante a própria busca, e/ou por alguma diferença na função de scoring, que talvez tenha passado despercebida pela nossa análise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
