{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descrição de Atividade\n",
    "\n",
    "Nessa atividade você irá usar seus conhecimentos sobre classificação para prever quais candidatos à Câmara de Deputados foram eleitos nas eleições de 2014. De forma específica:\n",
    "\n",
    " 1. Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador? Como você poderia tratar isso? (1 pt.)\n",
    " 2. Treine: um modelo de regressão logística, KNN, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.  (2 pts.)\n",
    "Reporte Precision, Recall e AUC-Precision&Recall no treino e validação. Há uma grande diferença de desempenho no treino/validação? Como você avalia os resultados? Justifique sua resposta. (2 pt.)\n",
    " 3. Interprete as saídas dos modelos. Quais atributos parecem ser mais importantes de acordo com cada modelo?  (2 pts.)\n",
    " 4. Envie seus melhores modelos à competição do Kaggle. Faça pelo menos uma submissão. Sugestões para melhorar o modelo: (2 pts.)\n",
    " 5. Experimente outros modelos (e.g. SVM, RandomForests e GradientBoosting).\n",
    " 6. Experimente outras estratégias de ensembles (e.g. Stacking).\n",
    " 7. Experimente balancear as classes,  caso estejam desbalanceadas.\n",
    "\n",
    "Os dados estão neste link: https://www.kaggle.com/c/ufcg-cdp-20182-lab3/data. Links para um site externo\n",
    "\n",
    "Para a entrega envie o link no GitHub com o notebook usado para resolver o Lab.\n",
    "\n",
    "\n",
    "### Descrição dos dados:\n",
    "\n",
    "Os dados utilizados correspondem aos das eleições de Deputado Federal nos anos de 2006, 2010 e 2014. Estão dividos nas seguintes colunas:\n",
    "\n",
    "* **ano**: Ano da eleição;\n",
    "* **sequencial_candidato**: O identificador do candidato. Corresponde à coluna Id do arquivo de submissão;\n",
    "* **nome**: Nome do candidato;\n",
    "* **uf**: Sigla do estado do candidato;\n",
    "* **partido**: Partido do candidato;\n",
    "* **quantidade_doacoes**: Número de doações que um candidato recebeu;\n",
    "* **quantidade_doadores**: Numero de doadores que um candidato teve;\n",
    "* **total_receita**: Total de receita de um candidato;\n",
    "* **media_receita**: Média da receita de um candidato;\n",
    "* **recursos_de_outros_candidatos.comites**: Total de receita proveniente de outros candidatos e comitês;\n",
    "* **recursos_de_pessoas_fisicas**: Total de receita proveniente de pessoas físicas;\n",
    "* **recursos_de_pessoas_juridicas**: Total de receita proveniente de pessoas juridicas;\n",
    "* **recursos_proprios**:Total de receita proveniente dos próprios candidatos;\n",
    "* **recursos_de_partido_politico**: Total de receita proveniente do partido do candidato;\n",
    "* **quantidade_despesas**: Número de despesas que um candidato teve;\n",
    "* **quantidade_fornecedores**: Número de fornecedores que um candidato teve;\n",
    "* **total_despesa**: Total de depesa de um candidato;\n",
    "* **media_despesa**: Média da despesa de um candidato;\n",
    "* **cargo**: Cargo ao qual o candidato está concorrendo;\n",
    "* **sexo**: Sexo do candidato;\n",
    "* **grau**: Grau de escolaridade do candidato;\n",
    "* **estado_civil**: Estado civil do candidato;\n",
    "* **ocupacao**: Ocupação do candidato;\n",
    "* **situacao**: Situação final do candidato. Corresponde à coluna **Predict** do arquivo de submissão;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, auc\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_validate, cross_val_predict\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "sns.set(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/assignment_4/train.csv')\n",
    "test_df = pd.read_csv('../data/assignment_4/test.csv')\n",
    "\n",
    "data = pd.concat([train_df, test_df], sort=False)\n",
    "\n",
    "data.set_index('sequencial_candidato', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['nome'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = QuantileTransformer(random_state=2, output_distribution='normal')\n",
    "\n",
    "skewed_features = ['quantidade_doacoes', 'quantidade_doadores', 'total_receita',\n",
    "       'media_receita', 'recursos_de_outros_candidatos.comites',\n",
    "       'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "       'recursos_proprios', 'recursos_de_partido_politico',\n",
    "       'quantidade_despesas', 'quantidade_fornecedores', 'total_despesa',\n",
    "       'media_despesa']\n",
    "\n",
    "data[skewed_features] = qt.fit_transform(X=data[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_nums = {\"grau\" : {\"LÊ E ESCREVE\": 1, \n",
    "                       \"ENSINO FUNDAMENTAL INCOMPLETO\":2, \n",
    "                       \"ENSINO FUNDAMENTAL COMPLETO\":3, \n",
    "                       \"ENSINO MÉDIO INCOMPLETO\":4,\n",
    "                       \"ENSINO MÉDIO COMPLETO\":5,\n",
    "                       \"SUPERIOR INCOMPLETO\":6,\n",
    "                       \"SUPERIOR COMPLETO\": 7}}\n",
    "\n",
    "data.replace(cleanup_nums, inplace=True)\n",
    "data[\"grau\"] = pd.to_numeric(data[\"grau\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12214, 258)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feats = [col for col in data.columns if not np.issubdtype(data[str(col)].dtype, np.number) and col not in ['nome', 'situacao']]\n",
    "\n",
    "data = pd.get_dummies(data, columns=categorical_feats)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7622, 259)\n",
      "(4592, 259)\n"
     ]
    }
   ],
   "source": [
    "data['situacao_dummy'] = data['situacao'].map({'eleito': 1, 'nao_eleito': 0})\n",
    "\n",
    "train = data[(data.ano == 2006) | (data.ano == 2010)]\n",
    "test = data[data.ano == 2014]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Class Imbalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7faf9083f9b0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='situacao', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de candidatos Eleitos: 1026\n",
      "Número de candidatos Não-Eleitos: 6596\n",
      "Total de candidatos: 7622\n",
      "\n",
      "Proporção de candidatos eleitos: 13.46%\n",
      "Proporção de candidatos não-eleitos: 86.54%\n"
     ]
    }
   ],
   "source": [
    "num_elected_candidates = train.situacao[train.situacao == 'eleito'].count()\n",
    "num_not_elected_candidates = train.situacao[train.situacao == 'nao_eleito'].count()\n",
    "total_candidates = train.shape[0]\n",
    "\n",
    "print(\"Número de candidatos Eleitos: {}\".format(num_elected_candidates))\n",
    "print(\"Número de candidatos Não-Eleitos: {}\".format(num_not_elected_candidates))\n",
    "print(\"Total de candidatos: {}\\n\".format(total_candidates))\n",
    "\n",
    "print(\"Proporção de candidatos eleitos: {:2.2%}\".format((num_elected_candidates/total_candidates)))\n",
    "print(\"Proporção de candidatos não-eleitos: {:2.2%}\".format((num_not_elected_candidates/total_candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável alvo **situacao** é bastante _desbalanceada_, em uma proporção de aproximadamente 1 eleito para cada 6 não-eleitos. Precisamente 13.46% dos candidatos foram eleitos, enquanto 86.54% não foram eleitos.\n",
    "\n",
    "#### Tratando Desbalanceamento\n",
    "\n",
    "Esse desbalanceamento pode causar alguns efeitos colaterais na classificação feita pelo modelo preditor, tais como overfitting do modelo em relação à classe majoritária, o que prejudica a acurácia da predição, podendo causar até mesmo a interpretação incorreta dos resultados se o desbalanceamento não for endereçado corretamente.\n",
    "\n",
    "Existem algumas práticas que podemos adotar para corrigir e lidar com esse desbalanceamento, a saber:\n",
    "\n",
    "* Coleta de mais dados, que poderia rebalancear as classes, a depender da natureza do problema;\n",
    "* Mudar a forma de amostragem do dataset, a qual pode estar gerando uma amostra desbalanceada, contudo o dataset não está desbalanceado;\n",
    "* Usar alguma forma de gerar dados sintéticos como Synthetic Minority Over-sampling Technique [SMOTE](https://imbalanced-learn.org/en/stable/over_sampling.html#cbhk2002) e Adaptive Synthetic [ADASYN](https://imbalanced-learn.org/en/stable/over_sampling.html#hbgl2008);\n",
    "* Incorporar algum modelo que tem uma forma de penalização para compensar o desbalanceamento de classes a exemplo de penalized-LDA e penalized-SVM.\n",
    "\n",
    "\n",
    "Para essa atividade nós usaremos a técnica de geração de dados sintéticos SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train SMOTE: [(0.0, 6596), (1.0, 6596)]\n",
      "Test.shape: (4592, 257)\n"
     ]
    }
   ],
   "source": [
    "train.drop(['situacao'], axis=1, inplace=True)\n",
    "test.drop(['situacao', 'situacao_dummy'], axis=1, inplace=True)\n",
    "\n",
    "X = train.loc[:, train.columns != 'situacao_dummy']\n",
    "y = train.situacao_dummy\n",
    "\n",
    "X_train, y_train = SMOTE().fit_resample(X, y)\n",
    "print(\"Train SMOTE: {}\".format(sorted(Counter(y_train).items())))\n",
    "\n",
    "#X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "\n",
    "X_test = test\n",
    "print(\"Test.shape: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enumerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelsPaths(Enum):\n",
    "    KNR_PATH = 'assignment4-models/knr.p'\n",
    "    LR_PATH = 'assignment4-models/lr.p'\n",
    "    DT_PATH = 'assignment4-models/dt.p'\n",
    "    ADA_PATH = 'assignment4-models/ada.p'\n",
    "    RF_PATH = 'assignment4-models/rf.p'\n",
    "    ET_PATH = 'assignment4-models/et.p'\n",
    "    SVC_PATH = 'assignment4-models/svc.p'\n",
    "    LGBM_PATH = 'assignment4-models/lgbm.p'\n",
    "    CAT_PATH = 'assignment4-models/cat.p'\n",
    "    XGB_PATH = 'assignment4-models/xgb.p'\n",
    "\n",
    "class ModelsNames(Enum):\n",
    "    LR = 'Logistic Regression'\n",
    "    DT = 'Decision Trees'\n",
    "    ET = 'Extra Trees'\n",
    "    RF = 'Random Forest'\n",
    "    ADA = 'AdaBoost'\n",
    "    SVC = 'Support Vector Machine'\n",
    "    LGBM = 'LGBM'\n",
    "    CAT = 'CatBoost'\n",
    "    XGB = 'XGBoost'\n",
    "    KNR = 'KNR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    'solver': 'liblinear'\n",
    "}\n",
    "\n",
    "knr_params = {\n",
    "    'n_neighbors': 3\n",
    "}\n",
    "\n",
    "dt_params = {\n",
    "    \n",
    "}\n",
    "\n",
    "ada_params = {\n",
    "    'learning_rate': 0.5\n",
    "}\n",
    "\n",
    "et_params = {\n",
    "\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    \n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    'probability': True,\n",
    "    'gamma' : 'auto'\n",
    "}\n",
    "\n",
    "lightgbm_params = {\n",
    "    #'n_estimators':200,\n",
    "    'learning_rate':0.1,\n",
    "    #'num_leaves':123,\n",
    "    #'colsample_bytree':0.8,\n",
    "    #'subsample':0.9,\n",
    "    #'max_depth':15,\n",
    "    #'reg_alpha':0.1,\n",
    "    #'reg_lambda':0.1,\n",
    "    #'min_split_gain':0.01,\n",
    "    #'min_child_weight':2  ,\n",
    "    'silent': 1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "catboost_params = {\n",
    "    'iterations': 200,\n",
    "    'learning_rate': 0.5,\n",
    "    'depth': 3,\n",
    "    #'l2_leaf_reg': 40,\n",
    "    #'bootstrap_type': 'Bernoulli',\n",
    "    #'subsample': 0.7,\n",
    "    #'scale_pos_weight': 5,\n",
    "    'eval_metric': 'AUC',\n",
    "    #'od_type': 'Iter',\n",
    "    'allow_writing_files': False,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    #'colsample_bytree': 0.7,\n",
    "    'silent': 1,\n",
    "    #'subsample': 0.7,\n",
    "    'learning_rate': 0.1,\n",
    "    'objective': 'binary:logistic',\n",
    "    #'max_depth': 2,\n",
    "    #'num_parallel_tree': 1,\n",
    "    #'min_child_weight': 1,\n",
    "    'nrounds': 250\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Random Forest Classifier\n",
      "Best params: {'clf__max_depth': 20, 'clf__random_state': 42}\n",
      "Best F1 score for training set: 0.9440\n",
      "Test set F1 score for best params: 0.9464 \n",
      "----------------\n",
      "\n",
      "Estimator: Decision Trees\n",
      "Best params: {'clf__max_depth': 10, 'clf__random_state': 42}\n",
      "Best F1 score for training set: 0.9341\n",
      "Test set F1 score for best params: 0.9358 \n",
      "----------------\n",
      "\n",
      "Estimator: AdaBoost Classifier\n",
      "Best params: {'clf__learning_rate': 0.5, 'clf__n_estimators': 50, 'clf__random_state': 42}\n",
      "Best F1 score for training set: 0.9386\n",
      "Test set F1 score for best params: 0.9326 \n",
      "----------------\n",
      "\n",
      "Estimator: KNN Classifier\n",
      "Best params: {'clf__n_neighbors': 3}\n",
      "Best F1 score for training set: 0.9293\n",
      "Test set F1 score for best params: 0.9308 \n",
      "----------------\n",
      "\n",
      "Estimator: Extra Trees Classifier\n",
      "Best params: {'clf__max_depth': 100, 'clf__random_state': 42}\n",
      "Best F1 score for training set: 0.9553\n",
      "Test set F1 score for best params: 0.9619 \n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "NFOLDS = 3\n",
    "SEED = 42\n",
    "\n",
    "# Construct some pipelines\n",
    "pipe_rf = Pipeline([('clf', RandomForestClassifier())])\n",
    "pipe_dt = Pipeline([('clf', DecisionTreeClassifier())])\n",
    "pipe_ad = Pipeline([('clf', AdaBoostClassifier())])\n",
    "pipe_kn = Pipeline([('clf', KNeighborsClassifier())])\n",
    "pipe_et = Pipeline([('clf', ExtraTreesClassifier())])\n",
    "#pipe_xg = Pipeline([('clf', XGBClassifier())])\n",
    "\n",
    "grid_params_rf = [{'clf__max_depth' : [2,10,20,100],\n",
    "                   'clf__random_state' : [SEED]}] \n",
    "\n",
    "grid_params_dt = [{'clf__max_depth' : [2,10,20,100],\n",
    "                  'clf__random_state' : [SEED]}]\n",
    "\n",
    "grid_params_ad = [{'clf__learning_rate' : [0.5],\n",
    "                   'clf__random_state': [SEED],\n",
    "                   'clf__n_estimators': [10, 20, 50]}]\n",
    "\n",
    "grid_params_kn = [{'clf__n_neighbors': [3]}]\n",
    "\n",
    "grid_params_et = [{'clf__max_depth' : [2,10,20,100],\n",
    "                  'clf__random_state' : [SEED]}]\n",
    "\n",
    "\n",
    "# Construct grid searches\n",
    "jobs = -1\n",
    "\n",
    "gs_rf = GridSearchCV(estimator = pipe_rf,\n",
    "                param_grid = grid_params_rf,\n",
    "                scoring = 'f1',\n",
    "                cv = NFOLDS) \n",
    "\n",
    "gs_dt = GridSearchCV(estimator = pipe_dt,\n",
    "                param_grid = grid_params_dt,\n",
    "                scoring = 'f1',\n",
    "                cv = NFOLDS)\n",
    "\n",
    "gs_ad = GridSearchCV(estimator = pipe_ad,\n",
    "                param_grid = grid_params_ad,\n",
    "                scoring = 'f1',\n",
    "                cv = NFOLDS)\n",
    "\n",
    "gs_kn = GridSearchCV(estimator = pipe_kn,\n",
    "                param_grid = grid_params_kn,\n",
    "                scoring = 'f1',\n",
    "                cv = NFOLDS)\n",
    "\n",
    "gs_et = GridSearchCV(estimator = pipe_et,\n",
    "                param_grid = grid_params_et,\n",
    "                scoring = 'f1',\n",
    "                cv = NFOLDS)\n",
    "\n",
    "# List of pipelines for ease of iteration\n",
    "grids = [gs_rf, gs_dt, gs_ad, gs_kn, gs_et]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "grid_dict = {0: 'Random Forest Classifier', 1: 'Decision Trees', 2: 'AdaBoost Classifier', \n",
    "            3: 'KNN Classifier', 4: 'Extra Trees Classifier', 5: 'XGBoost Classifier'}\n",
    "\n",
    "\n",
    "xx_train, xx_test, yy_train, yy_test = train_test_split(X_train, y_train)\n",
    "\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\n",
    "    \n",
    "    # Fit grid search\n",
    "    gs.fit(xx_train, yy_train)\n",
    "\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    \n",
    "    # Best training data accuracy\n",
    "    print('Best F1 score for training set: %.4f' % gs.best_score_)\n",
    "    \n",
    "    # Validation data accuracy of model with best params\n",
    "    print('Test set F1 score for best params: %.4f ' % f1_score(y_true=yy_test, y_pred=gs.predict(xx_test)))\n",
    "    \n",
    "    print(\"----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Definitions\n",
    "\n",
    "Abaixo definimos alguns wrappers para os modelos que vamos utilizar. Créditos para [**eliotbarr**](https://www.kaggle.com/eliotbarr/stacking-test-sklearn-xgboost-catboost-lightgbm/code) e [**arthurtok**](https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python) no Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = X_train.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "\n",
    "NFOLDS = 3\n",
    "SEED = 42\n",
    "\n",
    "class GenericWrapper(object):\n",
    "    def __init__(self, clf, params=None, model_name=None, model_path=None):\n",
    "        self.clf = clf(**params)\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.clf.fit(X_train, y_train)\n",
    "        self._save_trained_model()\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return self.clf.predict_proba(x)[:,1]\n",
    "    \n",
    "    def get_clf(self):\n",
    "        return self._load_trained_model()\n",
    "    \n",
    "    def _save_trained_model(self):\n",
    "        pickle.dump(self.clf, open(self.model_path, 'wb'))\n",
    "\n",
    "    def _load_trained_model(self):\n",
    "        return pickle.load(open(self.model_path, 'rb'))\n",
    "\n",
    "class SklearnWrapper_1(GenericWrapper):\n",
    "    def __init__(self, clf, seed=0, params=None, model_name=None, model_path=None):\n",
    "        params['random_state'] = seed\n",
    "        super().__init__(clf, params, model_name, model_path)\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        super().train(X_train, y_train)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super().predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return super().predict_proba(x)\n",
    "    \n",
    "    def get_clf(self):\n",
    "        return super().get_clf()\n",
    "    \n",
    "class SklearnWrapper_2(GenericWrapper):\n",
    "    def __init__(self, clf, params=None, model_name=None, model_path=None):\n",
    "        super().__init__(clf, params, model_name, model_path)\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        super().train(X_train, y_train)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super().predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return super().predict_proba(x)\n",
    "        \n",
    "    def get_clf(self):\n",
    "        return super().get_clf()\n",
    "    \n",
    "    \n",
    "class CatboostWrapper(GenericWrapper):\n",
    "    def __init__(self, clf, seed=0, params=None, model_name=None, model_path=None):\n",
    "        params['random_seed'] = seed\n",
    "        super().__init__(clf, params, model_name, model_path)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        super().train(X_train, y_train)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super().predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return super().predict_proba(x)\n",
    "    \n",
    "    def get_clf(self):\n",
    "        return super().get_clf()\n",
    "        \n",
    "\n",
    "class LightGBMWrapper(GenericWrapper):\n",
    "    def __init__(self, clf, seed=0, params=None, model_name=None, model_path=None):\n",
    "        params['feature_fraction_seed'] = seed\n",
    "        params['bagging_seed'] = seed\n",
    "        super().__init__(clf, params, model_name, model_path)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        super().train(X_train, y_train)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super().predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return super().predict_proba(x) \n",
    "    \n",
    "    def get_clf(self):\n",
    "        return super().get_clf()\n",
    "\n",
    "    \n",
    "class XgbWrapper(object):\n",
    "    def __init__(self, seed=0, params=None, model_name=None, model_path=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "        self.train_test_cols = [c for c in data.columns if c not in ['situacao', 'situacao_dummy']]\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(pd.DataFrame(x_train, columns=self.train_test_cols), label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "        \n",
    "        self._save_trained_model()\n",
    "\n",
    "    def predict(self, x):\n",
    "        preds = self.gbdt.predict(xgb.DMatrix(pd.DataFrame(x, columns=self.train_test_cols)))   \n",
    "        return [1 if x >= 0.5 else 0 for x in preds]\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(pd.DataFrame(x, columns=self.train_test_cols)))\n",
    "    \n",
    "    def _save_trained_model(self):\n",
    "        pickle.dump(self.gbdt, open(self.model_path, 'wb'))\n",
    "\n",
    "    def _load_trained_model(self):\n",
    "        return pickle.load(open(self.model_path, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GetOOF Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_proba = np.zeros((ntest,))\n",
    "    \n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "    oof_test_skf_proba = np.empty((NFOLDS, ntest))\n",
    "    \n",
    "    kf = StratifiedKFold(shuffle=True, random_state=SEED, n_splits=NFOLDS)\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "        x_tr = X_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = X_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(X_test)\n",
    "        oof_test_skf_proba[i, :] = clf.predict_proba(X_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    oof_test_proba[:] = oof_test_skf_proba.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1), oof_test_proba.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof_2(wp):\n",
    "    cv = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n",
    "    preds_train = cross_val_predict(wp.get_clf(), X_train, y_train, cv=cv, method='predict_proba')[:,1].reshape(-1,1)\n",
    "    return preds_train\n",
    "\n",
    "#add = SklearnWrapper_1(clf=AdaBoostClassifier, seed=SEED, params=ada_params, model_name=ModelsNames.ADA.value, model_path=ModelsPaths.ADA_PATH.value)\n",
    "#for m in mds: get_oof_2(add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Level Models Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9915433403805496"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp2 = LGBMClassifier().fit(X_train, y_train)\n",
    "preds = pp2.predict(X_train)\n",
    "f1_score(preds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    2.0s remaining:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   51.8s finished\n"
     ]
    }
   ],
   "source": [
    "ad = SklearnWrapper_1(clf=AdaBoostClassifier, seed=SEED, params=ada_params, model_name=ModelsNames.ADA.value, model_path=ModelsPaths.ADA_PATH.value)\n",
    "et = SklearnWrapper_1(clf=ExtraTreesClassifier, seed=SEED, params=et_params, model_name=ModelsNames.ET.value, model_path=ModelsPaths.ET_PATH.value)\n",
    "rf = SklearnWrapper_1(clf=RandomForestClassifier, seed=SEED, params=rf_params, model_name=ModelsNames.RF.value, model_path=ModelsPaths.RF_PATH.value)\n",
    "dt = SklearnWrapper_1(clf=DecisionTreeClassifier, seed=SEED, params=dt_params, model_name=ModelsNames.DT.value, model_path=ModelsPaths.DT_PATH.value)\n",
    "kn = SklearnWrapper_2(clf=KNeighborsClassifier, params=knr_params, model_name=ModelsNames.KNR.value, model_path=ModelsPaths.KNR_PATH.value)\n",
    "sv = SklearnWrapper_1(clf=SVC, seed=SEED, params=svc_params, model_name=ModelsNames.SVC.value, model_path=ModelsPaths.SVC_PATH.value)\n",
    "lr = SklearnWrapper_1(clf=LogisticRegression, params=lr_params, model_name=ModelsNames.LR.value, model_path=ModelsPaths.LR_PATH.value)\n",
    "lg = LightGBMWrapper(clf=LGBMClassifier, seed = SEED, params = lightgbm_params, model_name=ModelsNames.LGBM.value, model_path=ModelsPaths.LGBM_PATH.value)\n",
    "\n",
    "tasks = [ad, et, rf, dt, kn, sv, lr, lg]\n",
    "results = Parallel(n_jobs=-1, verbose=1)(delayed(get_oof_2)(md) for md in tasks)\n",
    "\n",
    "ad_oof_train = results[0]\n",
    "et_oof_train = results[1]\n",
    "rf_oof_train = results[2]\n",
    "dt_oof_train = results[3]\n",
    "kn_oof_train = results[4]\n",
    "sv_oof_train = results[5]\n",
    "lr_oof_train = results[6]\n",
    "lg_oof_train = results[7]\n",
    "\n",
    "ad_oof_test = ad.get_clf().predict_proba(X_test)[:,1].reshape(-1,1)\n",
    "et_oof_test = et.get_clf().predict_proba(X_test)[:,1].reshape(-1,1)\n",
    "rf_oof_test = rf.get_clf().predict_proba(X_test)[:,1].reshape(-1,1)\n",
    "dt_oof_test = dt.get_clf().predict_proba(X_test)[:,1].reshape(-1,1)\n",
    "kn_oof_test = kn.get_clf().predict_proba(X_test)[:,1].reshape(-1,1)\n",
    "sv_oof_test = sv.get_clf().predict_proba(X_test)[:,1].reshape(-1,1)\n",
    "lr_oof_test = lr.get_clf().predict_proba(X_test)[:,1].reshape(-1,1)\n",
    "lg_oof_test = lg.get_clf().predict_proba(X_test)[:,1].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_oof_2() missing 2 required positional arguments: 'x' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/guilherme/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 420, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/home/guilherme/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 563, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/guilherme/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 261, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/guilherme/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 261, in <listcomp>\n    for func, args, kwargs in self.items]\nTypeError: get_oof_2() missing 2 required positional arguments: 'x' and 'y'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-96059e35ffc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#tasks = [lr, ad, et, rf, dt, sv, kn, lg, cb, xg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0met\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_oof_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#lr_oof_train, lr_oof_test, lr_oof_test_proba = results[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-mestrado/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-mestrado/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_oof_2() missing 2 required positional arguments: 'x' and 'y'"
     ]
    }
   ],
   "source": [
    "lr = SklearnWrapper_1(clf=LogisticRegression, params=lr_params, model_name=ModelsNames.LR.value, model_path=ModelsPaths.LR_PATH.value)\n",
    "ad = SklearnWrapper_1(clf=AdaBoostClassifier, seed=SEED, params=ada_params, model_name=ModelsNames.ADA.value, model_path=ModelsPaths.ADA_PATH.value)\n",
    "et = SklearnWrapper_1(clf=ExtraTreesClassifier, seed=SEED, params=et_params, model_name=ModelsNames.ET.value, model_path=ModelsPaths.ET_PATH.value)\n",
    "rf = SklearnWrapper_1(clf=RandomForestClassifier, seed=SEED, params=rf_params, model_name=ModelsNames.RF.value, model_path=ModelsPaths.RF_PATH.value)\n",
    "dt = SklearnWrapper_1(clf=DecisionTreeClassifier, seed=SEED, params=dt_params, model_name=ModelsNames.DT.value, model_path=ModelsPaths.DT_PATH.value)\n",
    "sv = SklearnWrapper_1(clf=SVC, seed=SEED, params=svc_params, model_name=ModelsNames.SVC.value, model_path=ModelsPaths.SVC_PATH.value)\n",
    "kn = SklearnWrapper_2(clf=KNeighborsClassifier, params=knr_params, model_name=ModelsNames.KNR.value, model_path=ModelsPaths.KNR_PATH.value)\n",
    "lg = LightGBMWrapper(clf = LGBMClassifier, seed = SEED, params = lightgbm_params, model_name=ModelsNames.LGBM.value, model_path=ModelsPaths.LGBM_PATH.value)\n",
    "cb = CatboostWrapper(clf= CatBoostClassifier, seed = SEED, params=catboost_params, model_name=ModelsNames.CAT.value, model_path=ModelsPaths.CAT_PATH.value)\n",
    "xg = XgbWrapper(seed = SEED, params=xgb_params, model_name=ModelsNames.XGB.value, model_path=ModelsPaths.XGB_PATH.value)\n",
    "\n",
    "#tasks = [lr, ad, et, rf, dt, sv, kn, lg, cb, xg]\n",
    "tasks = [ad, et, rf, dt, kn, xg]\n",
    "results = Parallel(n_jobs=-1, verbose=1)(delayed(get_oof)(md) for md in tasks)\n",
    "\n",
    "#lr_oof_train, lr_oof_test, lr_oof_test_proba = results[0]\n",
    "ad_oof_train, ad_oof_test, ad_oof_test_proba = results[0]\n",
    "et_oof_train, et_oof_test, et_oof_test_proba = results[1]\n",
    "rf_oof_train, rf_oof_test, rf_oof_test_proba = results[2]\n",
    "dt_oof_train, dt_oof_test, dt_oof_test_proba = results[3]\n",
    "#sv_oof_train, sv_oof_test, sv_oof_test_proba = results[5]\n",
    "kn_oof_train, kn_oof_test, kn_oof_test_proba = results[4]\n",
    "#lg_oof_train, lg_oof_test, lg_oof_test_proba = results[7]\n",
    "#cb_oof_train, cb_oof_test, cb_oof_test_proba = results[8]\n",
    "xg_oof_train, xg_oof_test, xg_oof_test_proba = results[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Level Models Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoost\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-7e0e21d5f77c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mevaluate_inter_models_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-95-7e0e21d5f77c>\u001b[0m in \u001b[0;36mevaluate_inter_models_results\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_train_result\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision: {:.4}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_train_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall: {:.4}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_train_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F1: {:.4}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_train_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1270\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "def evaluate_inter_models_results(results):\n",
    "    for m_name, m_train_result in results:        \n",
    "        print(\"Model: {}\".format(m_name.value))\n",
    "        print(\"Precision: {:.4}\".format(precision_score(y_train, m_train_result)))\n",
    "        print(\"Recall: {:.4}\".format(recall_score(y_train, m_train_result)))\n",
    "        print(\"F1: {:.4}\".format(f1_score(y_train, m_train_result)))\n",
    "        print(\"Accuracy: {:.4}\".format(accuracy_score(y_train, m_train_result)))\n",
    "        print(\"Roc_auc: {:.4}\".format(roc_auc_score(y_train, m_train_result)))\n",
    "        print(\"----------------------\")\n",
    "\n",
    "#res = [(ModelsNames.LR, lr_oof_train), (ModelsNames.ADA, ad_oof_train), \n",
    "#   (ModelsNames.ET, et_oof_train), (ModelsNames.RF, rf_oof_train), \n",
    "#   (ModelsNames.DT, dt_oof_train), (ModelsNames.KNR, kn_oof_train), \n",
    "#   (ModelsNames.SVC, sv_oof_train), (ModelsNames.LGBM, lg_oof_train), \n",
    "#   (ModelsNames.CAT, cb_oof_train), (ModelsNames.XGB, xg_oof_train)]\n",
    "\n",
    "res = [(ModelsNames.ADA, ad_oof_train), \n",
    "   (ModelsNames.ET, et_oof_train), (ModelsNames.RF, rf_oof_train), \n",
    "   (ModelsNames.DT, dt_oof_train), (ModelsNames.KNR, kn_oof_train)]\n",
    "\n",
    "\n",
    "evaluate_inter_models_results(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances Plots\n",
    "\n",
    "Abaixo listamos as 10 features mais importantes elencadas por diferentes modelos que usamos, após o treinamento destes. Créditos para [**arthurtok**](https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python/notebook) no Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_top_10_features_and_imps(f_names, f_imps):\n",
    "    aux = [(f_name, f_imp) for f_idx_a, f_name in f_names for f_idx_b, f_imp in f_imps if f_idx_a == f_idx_b]\n",
    "    aux.sort(key=lambda tup: -tup[1]) # sort by feature_importance, descending order\n",
    "\n",
    "    top_10_features = aux[:10]\n",
    "    features_names = [x for x,_ in top_10_features]\n",
    "    features_imps = [y for _,y in top_10_features]\n",
    "\n",
    "    return (features_names, features_imps)\n",
    "\n",
    "def _get_feat_names_and_imps_1(model):\n",
    "    f_names = [(f_idx, f_name) for f_idx, f_name in enumerate(train.columns)]\n",
    "    f_imps = [(f_idx, f_imp) for f_idx, f_imp in enumerate(model.feature_importances_)]\n",
    "\n",
    "    return _get_top_10_features_and_imps(f_names, f_imps)\n",
    "\n",
    "def _get_feat_names_and_imps_2(model):\n",
    "    imps = (np.std(X_train, 0) * model.coef_)[0]\n",
    "\n",
    "    f_names = [(f_idx, f_name) for f_idx, f_name in enumerate(train.columns)]\n",
    "    f_imps = [(f_idx, f_imp) for f_idx, f_imp in enumerate(imps)]\n",
    "\n",
    "    return _get_top_10_features_and_imps(f_names, f_imps)\n",
    "\n",
    "\n",
    "def _plot_graph(model_name, features_names, features_imps):\n",
    "    # Scatter plot \n",
    "    trace = go.Scatter(\n",
    "        y = features_imps,\n",
    "        x = features_names,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            sizemode = 'diameter',\n",
    "            sizeref = 1,\n",
    "            size = 25,\n",
    "            color = features_imps,\n",
    "            colorscale='Portland',\n",
    "            showscale=True\n",
    "        ),\n",
    "        text = features_names\n",
    "    )\n",
    "    data = [trace]\n",
    "\n",
    "    layout= go.Layout(\n",
    "        autosize= True,\n",
    "        title= '{} Feature Importance'.format(model_name.value),\n",
    "        hovermode= 'closest',\n",
    "        yaxis=dict(\n",
    "            title= 'Feature Importance',\n",
    "            ticklen= 5,\n",
    "            gridwidth= 2\n",
    "        ),\n",
    "        showlegend= False\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig, filename='scatter2010')\n",
    "\n",
    "\n",
    "def plot_feature_importances(model, model_name):\n",
    "    feature_names, feature_imps = None,None\n",
    "\n",
    "    if model_name in [ModelsNames.DT, ModelsNames.ET, ModelsNames.RF, ModelsNames.ADA]:\n",
    "        feature_names, feature_imps = _get_feat_names_and_imps_1(model)\n",
    "    elif model_name in [ModelsNames.LR]:\n",
    "        feature_names, feature_imps = _get_feat_names_and_imps_2(model)\n",
    "\n",
    "    _plot_graph(model_name, feature_names, feature_imps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees, AdaBoost, Random Forest Classifier e Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = dt.get_clf() \n",
    "ad_clf = ad.get_clf() \n",
    "rf_clf = rf.get_clf() \n",
    "et_clf = et.get_clf() \n",
    "\n",
    "models = [(dt_clf, ModelsNames.DT), (ad_clf, ModelsNames.ADA), (rf_clf, ModelsNames.RF), (et_clf, ModelsNames.ET)]\n",
    "\n",
    "for model, model_name in models:\n",
    "    plot_feature_importances(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que esses modelos divergem quanto à principal feature que deve ser considerada para que um candidato seja eleito. Entretanto, podemos ver algumas que se repetem e que eles consideram como tendo maior importância:\n",
    "\n",
    "* total receita\n",
    "* ocupação Deputado (candidatos tentando reeleição)\n",
    "* total despesa\n",
    "* recursos obtidos (pessoas jurídicas, pessoas físicas, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = lr.get_clf()\n",
    "plot_feature_importances(lr_clf, ModelsNames.LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo de regressão logística atribui maior importância para a **quantidade de despesas** e a **quantidade de doadores** que um candidato possui como principais fatores para que ele se eleja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_clf = kn.get_clf() \n",
    "sv_clf = sv.get_clf() \n",
    "lg_clf = lg.get_clf() \n",
    "cb_clf = cb.get_clf() \n",
    "xg_clf = xg.get_clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Level Training - Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacked Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_stacked_model(model):\n",
    "    scoring = ['precision', 'recall', 'f1', 'accuracy', 'roc_auc']\n",
    "    scores = cross_validate(model, x__train, y__train, cv=3, scoring=scoring)\n",
    "    \n",
    "    print(\"\\nAvaliação de Stacked Model com CV:\")\n",
    "    print(\"Precision: {:.4}\".format(scores['test_precision'].mean()))\n",
    "    print(\"Recall: {:.4}\".format(scores['test_recall'].mean()))\n",
    "    print(\"F1: {:.4}\".format(scores['test_f1'].mean()))\n",
    "    print(\"Accuracy: {:.4}\".format(scores['test_accuracy'].mean()))\n",
    "    print(\"Roc_auc: {:.4}\".format(scores['test_roc_auc'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression-based Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x__train.shape: (13192, 4)\n",
      "y__train.shape: (13192,)\n",
      "x__test.shape:(4592, 4)\n",
      "\n",
      "Avaliação de Stacked Model com CV:\n",
      "Precision: 0.9523\n",
      "Recall: 0.961\n",
      "F1: 0.9561\n",
      "Accuracy: 0.9565\n",
      "Roc_auc: 0.993\n"
     ]
    }
   ],
   "source": [
    "x__train = np.concatenate((ad_oof_train, et_oof_train, kn_oof_train, lg_oof_train), axis=1)\n",
    "x__test = np.concatenate((ad_oof_test, et_oof_test, kn_oof_test, lg_oof_test), axis=1)\n",
    "\n",
    "y__train = y_train.copy()\n",
    "\n",
    "print(\"x__train.shape: {}\".format(x__train.shape))\n",
    "print(\"y__train.shape: {}\".format(y__train.shape))\n",
    "print(\"x__test.shape:{}\".format(x__test.shape))\n",
    "\n",
    "scoring = ['precision', 'recall', 'f1', 'accuracy', 'roc_auc']\n",
    "clf = LogisticRegression(solver='liblinear')\n",
    "clf.fit(x__train, y__train)\n",
    "\n",
    "evaluate_stacked_model(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Antes inserção de xgboost em versão com wrappers:\n",
    "* Avaliação de Stacked Model com CV:\n",
    "* Precision: 0.9486\n",
    "* Recall: 0.9616\n",
    "* F1: 0.9545\n",
    "* Accuracy: 0.9548\n",
    "* Roc_auc: 0.98\n",
    "\n",
    "Após inserção de xgboost em versão com wrappers:\n",
    "* Avaliação de Stacked Model com CV:\n",
    "* Precision: 0.9487\n",
    "* Recall: 0.9616\n",
    "* F1: 0.9546\n",
    "* Accuracy: 0.9549\n",
    "* Roc_auc: 0.9798\n",
    "\n",
    "Após tirar alguns modelos da versão final Stacked:\n",
    "* Avaliação de Stacked Model com CV:\n",
    "* Precision: 0.9426\n",
    "* Recall: 0.9753\n",
    "* F1: 0.9585\n",
    "* Accuracy: 0.958\n",
    "* Roc_auc: 0.9788\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Prediction to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000000135</td>\n",
       "      <td>nao_eleito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000000142</td>\n",
       "      <td>nao_eleito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000000158</td>\n",
       "      <td>nao_eleito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000000161</td>\n",
       "      <td>nao_eleito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000000163</td>\n",
       "      <td>eleito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000000164</td>\n",
       "      <td>nao_eleito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000000166</td>\n",
       "      <td>eleito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10000000169</td>\n",
       "      <td>nao_eleito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000000170</td>\n",
       "      <td>nao_eleito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000000171</td>\n",
       "      <td>eleito</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   Predicted\n",
       "0  10000000135  nao_eleito\n",
       "1  10000000142  nao_eleito\n",
       "2  10000000158  nao_eleito\n",
       "3  10000000161  nao_eleito\n",
       "4  10000000163      eleito\n",
       "5  10000000164  nao_eleito\n",
       "6  10000000166      eleito\n",
       "7  10000000169  nao_eleito\n",
       "8  10000000170  nao_eleito\n",
       "9  10000000171      eleito"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_df = pd.DataFrame(X_test.copy())\n",
    "pred = clf.predict(x__test)\n",
    "stack_df['Predicted'] = pred\n",
    "\n",
    "seq_candidato = stack_df.index\n",
    "\n",
    "stack_df.replace({'Predicted': {0: 'nao_eleito', 1: 'eleito'}}, inplace=True)\n",
    "stack_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "final_df = pd.DataFrame(columns=['Id','Predicted'])\n",
    "final_df['Id'] = seq_candidato\n",
    "final_df['Predicted'] = stack_df['Predicted']\n",
    "\n",
    "final_df.to_csv('../data/assignment_4/fourth_submission.csv', index=False)\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "origin_models = ['knr','lr','dt','ada','rf','svc','et','lgbm','cat','xgb']\n",
    "\n",
    "stack_df = pd.DataFrame(columns=origin_models + ['oracle'])\n",
    "\n",
    "stack_df['knr'] = knr.predict_proba(X_test)[:,1]\n",
    "stack_df['lr'] = lr.predict_proba(X_test)[:,1]\n",
    "stack_df['dt'] = dt.predict_proba(X_test)[:,1]\n",
    "stack_df['ada'] = ada.predict_proba(X_test)[:,1]\n",
    "stack_df['rf'] = rf.predict_proba(X_test)[:,1]\n",
    "stack_df['svc'] = svc.predict_proba(X_test)[:,1]\n",
    "stack_df['et'] = et.predict_proba(X_test)[:,1]\n",
    "stack_df['lgbm'] = lgbm.predict_proba(X_test)[:,1]\n",
    "stack_df['cat'] = cat.predict_proba(X_test)[:,1]\n",
    "stack_df['xgb'] = xgb.predict_proba(X_test)[:,1]\n",
    "stack_df['oracle'] = y_test\n",
    "\n",
    "stack_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previouslly:\n",
    "\n",
    "* Precision: 0.9481\n",
    "* Recall: 0.9884\n",
    "* F1: 0.9679\n",
    "* Accuracy: 0.9678\n",
    "* Roc_auc: 0.9682\n",
    "\n",
    "After add XGBoostClassifier:\n",
    "\n",
    "* Precision: 0.9658\n",
    "* Recall: 0.9807\n",
    "* F1: 0.9732\n",
    "* Accuracy: 0.9735\n",
    "* Roc_auc: 0.9736"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x__train, x__test, y__train, y__test = train_test_split(stack_df[origin_models], stack_df.oracle, test_size=0.2, random_state=42)\n",
    "\n",
    "stack_lr = LogisticRegression(solver='liblinear').fit(x__train, y__train)\n",
    "pred = stack_lr.predict(x__test)\n",
    "\n",
    "print('Precision: {:.4}'.format(precision_score(y__test, pred)))\n",
    "print('Recall: {:.4}'.format(recall_score(y__test, pred)))\n",
    "print('F1: {:.4}'.format(f1_score(y__test, pred)))\n",
    "print('Accuracy: {:.4}'.format(accuracy_score(y__test, pred)))\n",
    "print('Roc_auc: {:.4}'.format(roc_auc_score(y__test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
