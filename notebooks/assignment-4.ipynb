{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descrição de Atividade\n",
    "\n",
    "Nessa atividade você irá usar seus conhecimentos sobre classificação para prever quais candidatos à Câmara de Deputados foram eleitos nas eleições de 2014. De forma específica:\n",
    "\n",
    " 1. Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador? Como você poderia tratar isso? (1 pt.)\n",
    " 2. Treine: um modelo de regressão logística, KNN, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.  (2 pts.)\n",
    "Reporte Precision, Recall e AUC-Precision&Recall no treino e validação. Há uma grande diferença de desempenho no treino/validação? Como você avalia os resultados? Justifique sua resposta. (2 pt.)\n",
    " 3. Interprete as saídas dos modelos. Quais atributos parecem ser mais importantes de acordo com cada modelo?  (2 pts.)\n",
    " 4. Envie seus melhores modelos à competição do Kaggle. Faça pelo menos uma submissão. Sugestões para melhorar o modelo: (2 pts.)\n",
    " 5. Experimente outros modelos (e.g. SVM, RandomForests e GradientBoosting).\n",
    " 6. Experimente outras estratégias de ensembles (e.g. Stacking).\n",
    " 7. Experimente balancear as classes,  caso estejam desbalanceadas.\n",
    "\n",
    "Os dados estão neste link: https://www.kaggle.com/c/ufcg-cdp-20182-lab3/data (Links para um site externo)Links para um site externo\n",
    "\n",
    "Para a entrega envie o link no GitHub com o notebook usado para resolver o Lab.\n",
    "\n",
    "\n",
    "### Descrição dos dados:\n",
    "\n",
    "Os dados utilizados correspondem aos das eleições de Deputado Federal nos anos de 2006, 2010 e 2014. Estão dividos nas seguintes colunas:\n",
    "\n",
    "* **ano**: Ano da eleição;\n",
    "* **sequencial_candidato**: O identificador do candidato. Corresponde à coluna Id do arquivo de submissão;\n",
    "* **nome**: Nome do candidato;\n",
    "* **uf**: Sigla do estado do candidato;\n",
    "* **partido**: Partido do candidato;\n",
    "* **quantidade_doacoes**: Número de doações que um candidato recebeu;\n",
    "* **quantidade_doadores**: Numero de doadores que um candidato teve;\n",
    "* **total_receita**: Total de receita de um candidato;\n",
    "* **media_receita**: Média da receita de um candidato;\n",
    "* **recursos_de_outros_candidatos.comites**: Total de receita proveniente de outros candidatos e comitês;\n",
    "* **recursos_de_pessoas_fisicas**: Total de receita proveniente de pessoas físicas;\n",
    "* **recursos_de_pessoas_juridicas**: Total de receita proveniente de pessoas juridicas;\n",
    "* **recursos_proprios**:Total de receita proveniente dos próprios candidatos;\n",
    "* **recursos_de_partido_politico**: Total de receita proveniente do partido do candidato;\n",
    "* **quantidade_despesas**: Número de despesas que um candidato teve;\n",
    "* **quantidade_fornecedores**: Número de fornecedores que um candidato teve;\n",
    "* **total_despesa**: Total de depesa de um candidato;\n",
    "* **media_despesa**: Média da despesa de um candidato;\n",
    "* **cargo**: Cargo ao qual o candidato está concorrendo;\n",
    "* **sexo**: Sexo do candidato;\n",
    "* **grau**: Grau de escolaridade do candidato;\n",
    "* **estado_civil**: Estado civil do candidato;\n",
    "* **ocupacao**: Ocupação do candidato;\n",
    "* **situacao**: Situação final do candidato. Corresponde à coluna **Predict** do arquivo de submissão;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/assignment_4/train.csv')\n",
    "test_df = pd.read_csv('../data/assignment_4/test.csv')\n",
    "\n",
    "data = pd.concat([train_df, test_df], sort=False)\n",
    "\n",
    "data.set_index('sequencial_candidato', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = QuantileTransformer(random_state=2, output_distribution='normal')\n",
    "\n",
    "skewed_features = ['quantidade_doacoes', 'quantidade_doadores', 'total_receita',\n",
    "       'media_receita', 'recursos_de_outros_candidatos.comites',\n",
    "       'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "       'recursos_proprios', 'recursos_de_partido_politico',\n",
    "       'quantidade_despesas', 'quantidade_fornecedores', 'total_despesa',\n",
    "       'media_despesa']\n",
    "\n",
    "data[skewed_features] = qt.fit_transform(X=data[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_nums = {\"grau\" : {\"LÊ E ESCREVE\": 1, \n",
    "                       \"ENSINO FUNDAMENTAL INCOMPLETO\":2, \n",
    "                       \"ENSINO FUNDAMENTAL COMPLETO\":3, \n",
    "                       \"ENSINO MÉDIO INCOMPLETO\":4,\n",
    "                       \"ENSINO MÉDIO COMPLETO\":5,\n",
    "                       \"SUPERIOR INCOMPLETO\":6,\n",
    "                       \"SUPERIOR COMPLETO\": 7}}\n",
    "\n",
    "data.replace(cleanup_nums, inplace=True)\n",
    "data[\"grau\"] = pd.to_numeric(data[\"grau\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12214, 259)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feats = [col for col in data.columns if not np.issubdtype(data[str(col)].dtype, np.number) and col not in ['nome', 'situacao']]\n",
    "\n",
    "data = pd.get_dummies(data, columns=categorical_feats)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7622, 259)\n",
      "(4592, 259)\n"
     ]
    }
   ],
   "source": [
    "train = data[(data.ano == 2006) | (data.ano == 2010)]\n",
    "test = data[data.ano == 2014]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Class Unbalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1aaa96c6d8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='situacao', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de candidatos Eleitos: 1026\n",
      "Número de candidatos Não-Eleitos: 6596\n",
      "Total de candidatos: 7622\n",
      "\n",
      "Proporção de candidatos eleitos: 13.46%\n",
      "Proporção de candidatos não-eleitos: 86.54%\n"
     ]
    }
   ],
   "source": [
    "num_elected_candidates = train.situacao[train.situacao == 'eleito'].count()\n",
    "num_not_elected_candidates = train.situacao[train.situacao == 'nao_eleito'].count()\n",
    "total_candidates = train.shape[0]\n",
    "\n",
    "print(\"Número de candidatos Eleitos: {}\".format(num_elected_candidates))\n",
    "print(\"Número de candidatos Não-Eleitos: {}\".format(num_not_elected_candidates))\n",
    "print(\"Total de candidatos: {}\\n\".format(total_candidates))\n",
    "\n",
    "print(\"Proporção de candidatos eleitos: {:2.2%}\".format((num_elected_candidates/total_candidates)))\n",
    "print(\"Proporção de candidatos não-eleitos: {:2.2%}\".format((num_not_elected_candidates/total_candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável alvo **situacao** é bastante _desbalanceada_, em uma proporção de aproximadamente 1 eleito para cada 6 não-eleitos. Precisamente 13.46% dos candidatos foram eleitos, enquanto 86.54% não foram eleitos.\n",
    "\n",
    "Esse desbalanceamento pode causar alguns efeitos colaterais na classificação feita pelo modelo preditor, tais como overfitting do modelo em relação à classe majoritária, o que prejudica a acurácia da predição, podendo causar até mesmo a interpretação incorreta dos resultados se o desbalanceamento não for endereçado corretamente.\n",
    "\n",
    "Existem algumas práticas que podemos adotar para corrigir e lidar com esse desbalanceamento, a saber:\n",
    "\n",
    "* Coleta de mais dados, que poderia rebalancear as classes, a depender da natureza do problema;\n",
    "* Mudar a forma de amostragem do dataset, a qual pode estar gerando uma amostra desbalanceada, contudo o dataset não está desbalanceado;\n",
    "* Usar alguma forma de gerar dados sintéticos como Synthetic Minority Over-sampling Technique [SMOTE](https://imbalanced-learn.org/en/stable/over_sampling.html#cbhk2002) e Adaptive Synthetic [ADASYN](https://imbalanced-learn.org/en/stable/over_sampling.html#hbgl2008);\n",
    "* Incorporar algum modelo que tem uma forma de penalização para compensar o desbalanceamento de classes a exemplo de penalized-LDA e penalized-SVM;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos - Versão 1\n",
    "\n",
    "Nesta versão, utilizamos como dados de treino, os dados da eleição de 2006, e como dados de teste, os dados da eleição de 2010. Em um segundo momento, utilizaremos os dados da eleição de 2014 como dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_train = candidates_df[candidates_df.ano == 2006]\n",
    "candidates_val = candidates_df[candidates_df.ano == 2010]\n",
    "\n",
    "feats = candidates_df.columns[candidates_df.columns != 'votos']\n",
    "\n",
    "X_train = candidates_train[feats]\n",
    "y_train = candidates_train['votos']\n",
    "\n",
    "X_val = candidates_val[feats]\n",
    "y_val = candidates_val['votos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação Cruzada\n",
    "\n",
    "Abaixo definimos uma adaptação de uma função criada por Alexandru Papiu em [Regularized Linear Models](https://www.kaggle.com/apapiu/regularized-linear-models), que nos retorna a média dos RMSE's de um dado modelo para uma cross-validation no dataset de treino e um k-fold com k = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_rmse_cv(model):\n",
    "    return np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = 5)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Regularização\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "predictions = lr.predict(X_val)\n",
    "\n",
    "print(\"RMSE Linear Regressor - Train - Cross-Validated: {:2.3}\".format(mean_rmse_cv(lr)))\n",
    "print(\"RMSE Linear Regressor - Validation: {:2.3}\".format(np.sqrt(mean_squared_error(y_pred=predictions, y_true=y_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, os valores de RMSE para um modelo linear multivariado sem regularização tem um erro bastante elevado. Isso provavelmente se deve ao fato de está acontecendo overfitting. Uma simples olhada na ordem dos coeficientes do modelo nos permite observar isso. Caso os coeficientes sejam muito grandes, temos overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = lr.coef_\n",
    "ax = sns.distplot(coefs, kde=False)\n",
    "ax.set(xlabel='Valores dos Coeficientes', ylabel='Quantidade de Coeficientes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot Resíduos vs Predições - Linear Regressor**\n",
    "\n",
    "Abaixo nós plotamos o gráfico de resíduos vs predições. Ele nos possibilita visualizar o quão eficiente nosso modelo é para capturar a variância de nossos dados e representá-los de maneira adequada. O mais próximo que os valores de resíduos estiverem da linha demarcada (0), melhor será o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_val, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, nosso modelo feito com um Linear Regressor sem regularização não é um bom preditor: nós não observamos padrões visuais surgindo na distribuição dos resíduos, o que é um mal indício de adequabilidade do modelo, existem características que não estão sendo corretamente capturadas. E também os pontos estão concentrados aleatoriamente ao redor da linha nula (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com Regularização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Ridge_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\n",
    "\n",
    "ridge_train_rmses = []\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha).fit(X_train, y_train)\n",
    "    ridge_train_rmses.append(mean_rmse_cv(ridge))\n",
    "\n",
    "cv_ridge_train = pd.Series(ridge_train_rmses, index = alphas)\n",
    "\n",
    "cv_ridge_train.plot(title = \"Training Data\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor de **alpha** associado com o menor RMSE é **10**. Então vamos utilizar esse valor para configurar nosso modelo de regressão linear Ridge, o qual utiliza normalização **l2**. O valor de RMSE encontrado para alpha = 10 é em torno de 1.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ridge_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha = 10).fit(X_train, y_train)\n",
    "predictions = ridge.predict(X_val)\n",
    "print(\"RMSE Ridge Regressor - Train - Cross-Validated: {:2.7}\".format(mean_rmse_cv(ridge)))\n",
    "print(\"RMSE Ridge Regressor - Validation: {:2.7}\".format(np.sqrt(mean_squared_error(y_true=y_val, y_pred=predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot Resíduos vs Predições - Ridge**\n",
    "\n",
    "Abaixo nós plotamos o gráfico de resíduos vs predições. Ele nos possibilita visualizar o quão eficiente nosso modelo é para capturar a variância de nossos dados e representá-los de maneira adequada. O mais próximo que os valores de resíduos estiverem da linha demarcada (0), melhor será o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_val, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, nosso modelo Ridge é um regressor razoável: nós não observamos nenhum padrão visual na distribuição dos resíduos, o que é um bom indício de adequabilidade do modelo. E também os pontos estão concentrados próximos a linha nula (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Lasso_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso = LassoCV(alphas = [1, 5e-1, 1e-1, 5e-2, 1e-3, 1e-4, 1e-5, 1e-6], max_iter=1e5).fit(X_train, y_train)\n",
    "predictions = model_lasso.predict(X_val)\n",
    "print(\"RMSE Lasso Regressor - Train - Cross-Validated: {:2.7}\".format(mean_rmse_cv(model_lasso)))\n",
    "print(\"RMSE Lasso Regressor - Validation: {:2.7}\".format(np.sqrt(mean_squared_error(y_true=y_val, y_pred=predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo Ridge se sai um pouco melhor que o modelo Lasso. Complementando a análise, podemos identificar quais variáveis foram consideradas ou eliminadas pelo modelo de regressão Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(model_lasso.coef_, index = X_train.columns)\n",
    "\n",
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_coef = pd.concat([coef.sort_values().head(10), coef.sort_values().tail(10)])\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Lasso Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot Resíduos vs Predições - Lasso**\n",
    "\n",
    "Abaixo nós plotamos o gráfico de resíduos vs predições. Ele nos possibilita visualizar o quão eficiente nosso modelo é para capturar a variância de nossos dados e representá-los de maneira adequada. O mais próximo que os valores de resíduos estiverem da linha demarcada (0), melhor será o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_lasso.predict(X_val)\n",
    "sns.residplot(y_val, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, nosso modelo Lasso é um regressor razoável: nós não observamos nenhum padrão visual na distribuição dos resíduos, o que é um bom indício de adequabilidade do modelo. E também os pontos estão concentrados próximos a linha nula (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Parameterized Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_KNN (K-Nearest Neighbors)_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_rmse = []\n",
    "\n",
    "neighbors_settings = range(1, 20, 3)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    knr = KNeighborsRegressor(n_neighbors=n_neighbors).fit(X_train, y_train)\n",
    "    training_rmse.append(mean_rmse_cv(knr))\n",
    "    \n",
    "plt.plot(neighbors_settings, training_rmse, label=\"training rmse\")\n",
    "plt.ylabel(\"rmse\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente, o melhor número para K é 18, a partir do qual, os valores de acurácia começam a ser aproximadamente o mesmo. Vamos fazer a análise utilizando as funções para cálculo de RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knr = KNeighborsRegressor(n_neighbors = 18).fit(X_train, y_train)\n",
    "predictions = knr.predict(X_val)\n",
    "\n",
    "print(\"RMSE KNN Regressor - Train - Cross-Validated: {:2.7}\".format(mean_rmse_cv(knr)))\n",
    "print(\"RMSE KNN Regressor - Validation: {:2.7}\".format(np.sqrt(mean_squared_error(y_true=y_val, y_pred=predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot Resíduos vs Predições - KNN**\n",
    "\n",
    "Abaixo nós plotamos o gráfico de resíduos vs predições. Ele nos possibilita visualizar o quão eficiente nosso modelo é para capturar a variância de nossos dados e representá-los de maneira adequada. O mais próximo que os valores de resíduos estiverem da linha demarcada (0), melhor será o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_val, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos Extra\n",
    "\n",
    "Nessa sessão vamos testar a eficiência em termos de RMSE, quando utilizamos um Ensemble Random Forest Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Random Forest Regressor_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state = 2).fit(X_train, y_train)\n",
    "predictions = rf.predict(X_val)\n",
    "\n",
    "print(\"RMSE Random Forest Regressor - Train - Cross-Validated: {:2.7}\".format(mean_rmse_cv(rf)))\n",
    "print(\"RMSE Random Forest Regressor - Validation: {:2.7}\".format(np.sqrt(mean_squared_error(y_true=y_val, y_pred=predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot Resíduos vs Predições - Random Forest**\n",
    "\n",
    "Abaixo nós plotamos o gráfico de resíduos vs predições. Ele nos possibilita visualizar o quão eficiente nosso modelo é para capturar a variância de nossos dados e representá-los de maneira adequada. O mais próximo que os valores de resíduos estiverem da linha demarcada (0), melhor será o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_val, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _**Decision Tree Regressor**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(random_state = 2).fit(X_train, y_train)\n",
    "predictions = dt.predict(X_val)\n",
    "\n",
    "print(\"RMSE Decision Tree Regressor - Train - Cross-Validated: {:2.7}\".format(mean_rmse_cv(dt)))\n",
    "print(\"RMSE Decision Tree Regressor - Validation: {:2.7}\".format(np.sqrt(mean_squared_error(y_true=y_val, y_pred=predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot Resíduos vs Predições - Decision Tree Regressor**\n",
    "\n",
    "Abaixo nós plotamos o gráfico de resíduos vs predições. Ele nos possibilita visualizar o quão eficiente nosso modelo é para capturar a variância de nossos dados e representá-los de maneira adequada. O mais próximo que os valores de resíduos estiverem da linha demarcada (0), melhor será o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_val, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Epsilon-Support Vector Regressor_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR().fit(X_train, y_train)\n",
    "predictions = svr.predict(X_val)\n",
    "\n",
    "print(\"RMSE SVR - Train - Cross-Validated: {:2.7}\".format(mean_rmse_cv(svr)))\n",
    "print(\"RMSE SVR - Validation: {:2.7}\".format(np.sqrt(mean_squared_error(y_true=y_val, y_pred=predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot Resíduos vs Predições - SVR**\n",
    "\n",
    "Abaixo nós plotamos o gráfico de resíduos vs predições. Ele nos possibilita visualizar o quão eficiente nosso modelo é para capturar a variância de nossos dados e representá-los de maneira adequada. O mais próximo que os valores de resíduos estiverem da linha demarcada (0), melhor será o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_val, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, em termos de RMSE sobre os dados de validação o **Ridge Regressor** é o melhor modelo que encontramos até agora, com o modelo **Lasso Regressor** bem próximo a ele em termos de RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos - Versão 2\n",
    "\n",
    "Abaixo nós vamos unir os dados de treino e validação usados acima (eleições 2006 e 2010), retreinar o melhor algoritmo identificado e usar os dados de teste (eleição de 2014) para verificar seu desempenho em termos de RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo Variáveis Dependentes e Independentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = candidates_df.columns[candidates_df.columns != 'votos']\n",
    "\n",
    "X_train = candidates_df[feats]\n",
    "y_train = candidates_df['votos']\n",
    "\n",
    "X_test = candidates_test_df[feats]\n",
    "y_test = candidates_test_df['votos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Regularização\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_test)\n",
    "print(\"RMSE Linear Regressor - Test: {:2.5}\".format(np.sqrt(mean_squared_error(y_true=y_test, y_pred=predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot Resíduos vs Predições - Linear Regressor**\n",
    "\n",
    "Abaixo nós plotamos o gráfico de resíduos vs predições. Ele nos possibilita visualizar o quão eficiente nosso modelo é para capturar a variância de nossos dados e representá-los de maneira adequada. O mais próximo que os valores de resíduos estiverem da linha demarcada (0), melhor será o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, nosso modelo feito com um **Linear Regressor** sem regularização não é um bom preditor: nós não observamos padrões visuais surgindo na distribuição dos resíduos, o que é um mal indício de adequabilidade do modelo, existem características que não estão sendo corretamente capturadas. E também os pontos estão concentrados aleatoriamente ao redor da linha nula (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com Regularização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ridge.predict(X_test)\n",
    "print(\"RMSE Ridge Regressor - Test: {:2.10}\".format(np.sqrt(mean_squared_error(y_true=y_test, y_pred=predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot Resíduos vs Predições - Ridge**\n",
    "\n",
    "Abaixo nós plotamos o gráfico de resíduos vs predições. Ele nos possibilita visualizar o quão eficiente nosso modelo é para capturar a variância de nossos dados e representá-los de maneira adequada. O mais próximo que os valores de resíduos estiverem da linha demarcada (0), melhor será o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, nosso modelo **Ridge** é um regressor razoável: nós não observamos nenhum padrão visual na distribuição dos resíduos, o que é um bom indício de adequabilidade do modelo. E também os pontos estão concentrados próximos a linha nula (0).\n",
    "\n",
    "É possível observar também em destaque que o modelo não consegue prever com acurácia para os casos em que os candidatos recebem zero votos. Isso pode ser explicado pelo fato de se tratarem de **outliers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_lasso.predict(X_test)\n",
    "print(\"RMSE Lasso Regressor - Test: {:2.10}\".format(np.sqrt(mean_squared_error(y_true=y_test, y_pred=predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo **Lasso Regressor** se sai um pouco melhor que o modelo **Ridge Regressor**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot Resíduos vs Predições - Lasso**\n",
    "\n",
    "Abaixo nós plotamos o gráfico de resíduos vs predições. Ele nos possibilita visualizar o quão eficiente nosso modelo é para capturar a variância de nossos dados e representá-los de maneira adequada. O mais próximo que os valores de resíduos estiverem da linha demarcada (0), melhor será o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, nosso modelo **Lasso** é um regressor razoável: nós não observamos nenhum padrão visual na distribuição dos resíduos, o que é um bom indício de adequabilidade do modelo. E também os pontos estão concentrados próximos a linha nula (0).\n",
    "\n",
    "O modelo Lasso, assim como o Ridge, não consegue prever bem quando os candidatos recebem zero votos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Parameterized Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = knr.predict(X_test)\n",
    "print(\"RMSE KNN Regressor - Test: {:2.5}\".format(np.sqrt(mean_squared_error(y_true=y_test, y_pred=predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot Resíduos vs Predições - KNN**\n",
    "\n",
    "Abaixo nós plotamos o gráfico de resíduos vs predições. Ele nos possibilita visualizar o quão eficiente nosso modelo é para capturar a variância de nossos dados e representá-los de maneira adequada. O mais próximo que os valores de resíduos estiverem da linha demarcada (0), melhor será o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, nosso modelo **KNN** é um regressor razoável: nós não observamos nenhum padrão visual na distribuição dos resíduos, o que é um bom indício de adequabilidade do modelo. E também os pontos estão concentrados próximos a linha nula (0). Entretanto, o modelo não consegue prever bem quando os candidatos recebem zero votos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos Extra\n",
    "\n",
    "Nessa sessão vamos testar a eficiência em termos de RMSE, quando utilizamos um Ensemble Random Forest Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Random Forest Regressor_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf.predict(X_test)\n",
    "print(\"RMSE Random Forest Regressor - Test: {:2.10}\".format(np.sqrt(mean_squared_error(y_true=y_test, y_pred=predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot Resíduos vs Predições - Random Forests**\n",
    "\n",
    "Abaixo nós plotamos o gráfico de resíduos vs predições. Ele nos possibilita visualizar o quão eficiente nosso modelo é para capturar a variância de nossos dados e representá-los de maneira adequada. O mais próximo que os valores de resíduos estiverem da linha demarcada (0), melhor será o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, nosso modelo **Random Forest** é um regressor razoável: nós não observamos nenhum padrão visual na distribuição dos resíduos, o que é um bom indício de adequabilidade do modelo. E também os pontos estão concentrados próximos a linha nula (0). Entretanto, o modelo, assim como os demais até agora, não consegue prever bem quando os candidatos recebem zero votos.\n",
    "\n",
    "Como esses zero votos provavelmente são **outliers** é preciso dar um tratamento prévio a eles, antes de serem submetidos para criação do modelo preditivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Decision Tree Regressor_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dt.predict(X_test)\n",
    "print(\"RMSE Decision Tree Regressor - Test: {:2.10}\".format(np.sqrt(mean_squared_error(y_true=y_test, y_pred=predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot Resíduos vs Predições - Decision Tree Regressor**\n",
    "\n",
    "Abaixo nós plotamos o gráfico de resíduos vs predições. Ele nos possibilita visualizar o quão eficiente nosso modelo é para capturar a variância de nossos dados e representá-los de maneira adequada. O mais próximo que os valores de resíduos estiverem da linha demarcada (0), melhor será o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, nosso modelo **Decision Tree Regressor** é um regressor razoável: nós não observamos nenhum padrão visual na distribuição dos resíduos, o que é um bom indício de adequabilidade do modelo. E também os pontos estão concentrados próximos a linha nula (0). Entretanto, o modelo não consegue prever bem quando os candidatos recebem zero votos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Epsilon-Support Vector Regressor_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svr.predict(X_test)\n",
    "print(\"RMSE SVR - Test: {:2.10}\".format(np.sqrt(mean_squared_error(y_true=y_test, y_pred=predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot Resíduos vs Predições - SVR**\n",
    "\n",
    "Abaixo nós plotamos o gráfico de resíduos vs predições. Ele nos possibilita visualizar o quão eficiente nosso modelo é para capturar a variância de nossos dados e representá-los de maneira adequada. O mais próximo que os valores de resíduos estiverem da linha demarcada (0), melhor será o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, nosso modelo **SVR** é um regressor razoável: nós não observamos nenhum padrão visual na distribuição dos resíduos, o que é um bom indício de adequabilidade do modelo. E também os pontos estão concentrados próximos a linha nula (0). Entretanto, o modelo não consegue prever bem quando os candidatos recebem zero votos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, o melhor modelo quando utilizamos os dados de teste é o modelo **Lasso Regressor**, com o modelo **Ridge Regressor** bem próximo dele em termos de RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA - Usando Pipelines e GridSearch do Scikit Learn\n",
    "\n",
    "Abaixo nós fazemos alguns pipelines e grid searches com os mesmos algoritmos usados acima com o intuito de checar se os valores obtidos são correspondentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def rmse_function(y_pred, y_true):\n",
    "    return np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
    "\n",
    "scorer = make_scorer(rmse_function, greater_is_better=False)\n",
    "\n",
    "# Construct some pipelines\n",
    "pipe_lr = Pipeline([('reg', LinearRegression())])\n",
    "pipe_rf = Pipeline([('reg', RandomForestRegressor())])\n",
    "pipe_lasso = Pipeline([('reg', LassoCV())])\n",
    "pipe_ridge = Pipeline([('reg', RidgeCV())])\n",
    "pipe_knn = Pipeline([('reg', KNeighborsRegressor())])\n",
    "pipe_dt = Pipeline([('reg', DecisionTreeRegressor())])\n",
    "pipe_svr = Pipeline([('reg', SVR())])\n",
    "\n",
    "\n",
    "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "grid_params_lr = [{}] \n",
    "\n",
    "grid_params_lasso = [{'reg__alphas' : [[5e-1, 1e-1, 5e-2, 1e-3, 1e-4, 1e-5, 1e-6]],\n",
    "                      'reg__max_iter' : [1e5],\n",
    "                      'reg__random_state' : [2]}]\n",
    "\n",
    "grid_params_ridge = [{'reg__alphas' : [[0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]]}]\n",
    "\n",
    "grid_params_rf = [{}]\n",
    "\n",
    "grid_params_knn = [{'reg__n_neighbors' : [1, 3, 5, 7, 10, 15, 18, 21]}]\n",
    "\n",
    "grid_params_dt = [{'reg__random_state' : [2],\n",
    "                   'reg__max_depth' : [5, 10, 50]}]\n",
    "\n",
    "grid_params_svr = [{'reg__C': [1e0, 1e1, 1e2, 1e3]}]\n",
    "\n",
    "# Construct grid searches\n",
    "jobs = -1\n",
    "\n",
    "gs_lr = GridSearchCV(estimator = pipe_lr,\n",
    "                param_grid = grid_params_lr,\n",
    "                scoring = scorer,\n",
    "                cv = 5) \n",
    "\n",
    "gs_rf = GridSearchCV(estimator = pipe_rf,\n",
    "                param_grid = grid_params_rf,\n",
    "                scoring = scorer,\n",
    "                cv = 5, \n",
    "                n_jobs = jobs)\n",
    "\n",
    "gs_lasso = GridSearchCV(estimator = pipe_lasso,\n",
    "                       param_grid = grid_params_lasso,\n",
    "                       scoring = scorer,\n",
    "                       cv = 5,\n",
    "                       n_jobs = jobs)\n",
    "\n",
    "gs_ridge = GridSearchCV(estimator = pipe_ridge,\n",
    "                       param_grid = grid_params_ridge,\n",
    "                       scoring = scorer,\n",
    "                       cv = 5,\n",
    "                       n_jobs = jobs)\n",
    "\n",
    "gs_knn = GridSearchCV(estimator = pipe_knn,\n",
    "                     param_grid = grid_params_knn,\n",
    "                     scoring = scorer,\n",
    "                     cv = 5,\n",
    "                     n_jobs = jobs)\n",
    "\n",
    "gs_dt = GridSearchCV(estimator = pipe_dt,\n",
    "                    param_grid = grid_params_dt,\n",
    "                    scoring = scorer,\n",
    "                    cv = 5,\n",
    "                    n_jobs = jobs)\n",
    "\n",
    "gs_svr = GridSearchCV(estimator = pipe_svr,\n",
    "                     param_grid = grid_params_svr,\n",
    "                     scoring = scorer,\n",
    "                     cv = 5,\n",
    "                     n_jobs = jobs)\n",
    "\n",
    "# List of pipelines for ease of iteration\n",
    "grids = [gs_lr, gs_rf, gs_ridge, gs_lasso, gs_knn, gs_dt, gs_svr]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "grid_dict = {0: 'Linear Regressor', 1: 'Random Forest Regressor', \n",
    "            2: 'Ridge Regressor', 3: 'Lasso Regressor', \n",
    "            4: 'KNN Regressor', 5: 'Decision Tree Regressor',\n",
    "            6: 'SVR Regressor'}\n",
    "\n",
    "\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_rmse = float(\"inf\")\n",
    "best_reg = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\n",
    "    # Fit grid search\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    \n",
    "    # Best training data accuracy\n",
    "    print('Best RMSE for training set: %.10f' % -gs.best_score_)\n",
    "    \n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_pred))\n",
    "    \n",
    "    # Validation data accuracy of model with best params\n",
    "    print('Test set RMSE for best params: %.10f ' % rmse)\n",
    "    \n",
    "    # Track best (smallest rmse) model\n",
    "    if best_rmse > rmse:\n",
    "        best_rmse = rmse\n",
    "        best_gs = gs\n",
    "        best_reg = idx\n",
    "        \n",
    "print('\\nRegressor with best test set RMSE: ** %s **' % grid_dict[best_reg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "Como se observa acima, o melhor modelo encontrado foi o modelo **Lasso Regressor** em termos de RMSE, com o modelo **Ridge Regressor** bem próximo dele em termos de RMSE.\n",
    "\n",
    "Entretanto os valores de RMSE são distintos dos valores encontrados acima. Isso pode se dever ao ajuste dos parâmetros dos modelos, feitos durante a própria busca, e/ou por alguma diferença na função de scoring, que talvez tenha passado despercebida pela nossa análise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
