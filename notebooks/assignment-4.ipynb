{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descrição de Atividade\n",
    "\n",
    "Nessa atividade você irá usar seus conhecimentos sobre classificação para prever quais candidatos à Câmara de Deputados foram eleitos nas eleições de 2014. De forma específica:\n",
    "\n",
    " 1. Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador? Como você poderia tratar isso? (1 pt.)\n",
    " 2. Treine: um modelo de regressão logística, KNN, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.  (2 pts.)\n",
    "Reporte Precision, Recall e AUC-Precision&Recall no treino e validação. Há uma grande diferença de desempenho no treino/validação? Como você avalia os resultados? Justifique sua resposta. (2 pt.)\n",
    " 3. Interprete as saídas dos modelos. Quais atributos parecem ser mais importantes de acordo com cada modelo?  (2 pts.)\n",
    " 4. Envie seus melhores modelos à competição do Kaggle. Faça pelo menos uma submissão. Sugestões para melhorar o modelo: (2 pts.)\n",
    " 5. Experimente outros modelos (e.g. SVM, RandomForests e GradientBoosting).\n",
    " 6. Experimente outras estratégias de ensembles (e.g. Stacking).\n",
    " 7. Experimente balancear as classes,  caso estejam desbalanceadas.\n",
    "\n",
    "Os dados estão neste link: https://www.kaggle.com/c/ufcg-cdp-20182-lab3/data (Links para um site externo)Links para um site externo\n",
    "\n",
    "Para a entrega envie o link no GitHub com o notebook usado para resolver o Lab.\n",
    "\n",
    "\n",
    "### Descrição dos dados:\n",
    "\n",
    "Os dados utilizados correspondem aos das eleições de Deputado Federal nos anos de 2006, 2010 e 2014. Estão dividos nas seguintes colunas:\n",
    "\n",
    "* **ano**: Ano da eleição;\n",
    "* **sequencial_candidato**: O identificador do candidato. Corresponde à coluna Id do arquivo de submissão;\n",
    "* **nome**: Nome do candidato;\n",
    "* **uf**: Sigla do estado do candidato;\n",
    "* **partido**: Partido do candidato;\n",
    "* **quantidade_doacoes**: Número de doações que um candidato recebeu;\n",
    "* **quantidade_doadores**: Numero de doadores que um candidato teve;\n",
    "* **total_receita**: Total de receita de um candidato;\n",
    "* **media_receita**: Média da receita de um candidato;\n",
    "* **recursos_de_outros_candidatos.comites**: Total de receita proveniente de outros candidatos e comitês;\n",
    "* **recursos_de_pessoas_fisicas**: Total de receita proveniente de pessoas físicas;\n",
    "* **recursos_de_pessoas_juridicas**: Total de receita proveniente de pessoas juridicas;\n",
    "* **recursos_proprios**:Total de receita proveniente dos próprios candidatos;\n",
    "* **recursos_de_partido_politico**: Total de receita proveniente do partido do candidato;\n",
    "* **quantidade_despesas**: Número de despesas que um candidato teve;\n",
    "* **quantidade_fornecedores**: Número de fornecedores que um candidato teve;\n",
    "* **total_despesa**: Total de depesa de um candidato;\n",
    "* **media_despesa**: Média da despesa de um candidato;\n",
    "* **cargo**: Cargo ao qual o candidato está concorrendo;\n",
    "* **sexo**: Sexo do candidato;\n",
    "* **grau**: Grau de escolaridade do candidato;\n",
    "* **estado_civil**: Estado civil do candidato;\n",
    "* **ocupacao**: Ocupação do candidato;\n",
    "* **situacao**: Situação final do candidato. Corresponde à coluna **Predict** do arquivo de submissão;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/assignment_4/train.csv')\n",
    "test_df = pd.read_csv('../data/assignment_4/test.csv')\n",
    "\n",
    "data = pd.concat([train_df, test_df], sort=False)\n",
    "\n",
    "data.set_index('sequencial_candidato', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['nome'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = QuantileTransformer(random_state=2, output_distribution='normal')\n",
    "\n",
    "skewed_features = ['quantidade_doacoes', 'quantidade_doadores', 'total_receita',\n",
    "       'media_receita', 'recursos_de_outros_candidatos.comites',\n",
    "       'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "       'recursos_proprios', 'recursos_de_partido_politico',\n",
    "       'quantidade_despesas', 'quantidade_fornecedores', 'total_despesa',\n",
    "       'media_despesa']\n",
    "\n",
    "data[skewed_features] = qt.fit_transform(X=data[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_nums = {\"grau\" : {\"LÊ E ESCREVE\": 1, \n",
    "                       \"ENSINO FUNDAMENTAL INCOMPLETO\":2, \n",
    "                       \"ENSINO FUNDAMENTAL COMPLETO\":3, \n",
    "                       \"ENSINO MÉDIO INCOMPLETO\":4,\n",
    "                       \"ENSINO MÉDIO COMPLETO\":5,\n",
    "                       \"SUPERIOR INCOMPLETO\":6,\n",
    "                       \"SUPERIOR COMPLETO\": 7}}\n",
    "\n",
    "data.replace(cleanup_nums, inplace=True)\n",
    "data[\"grau\"] = pd.to_numeric(data[\"grau\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12214, 258)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feats = [col for col in data.columns if not np.issubdtype(data[str(col)].dtype, np.number) and col not in ['nome', 'situacao']]\n",
    "\n",
    "data = pd.get_dummies(data, columns=categorical_feats)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7622, 259)\n",
      "(4592, 259)\n"
     ]
    }
   ],
   "source": [
    "data['situacao_dummy'] = data['situacao'].map({'eleito': 1, 'nao_eleito': 0})\n",
    "\n",
    "train = data[(data.ano == 2006) | (data.ano == 2010)]\n",
    "test = data[data.ano == 2014]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Class Imbalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa957df0a20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='situacao', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de candidatos Eleitos: 1026\n",
      "Número de candidatos Não-Eleitos: 6596\n",
      "Total de candidatos: 7622\n",
      "\n",
      "Proporção de candidatos eleitos: 13.46%\n",
      "Proporção de candidatos não-eleitos: 86.54%\n"
     ]
    }
   ],
   "source": [
    "num_elected_candidates = train.situacao[train.situacao == 'eleito'].count()\n",
    "num_not_elected_candidates = train.situacao[train.situacao == 'nao_eleito'].count()\n",
    "total_candidates = train.shape[0]\n",
    "\n",
    "print(\"Número de candidatos Eleitos: {}\".format(num_elected_candidates))\n",
    "print(\"Número de candidatos Não-Eleitos: {}\".format(num_not_elected_candidates))\n",
    "print(\"Total de candidatos: {}\\n\".format(total_candidates))\n",
    "\n",
    "print(\"Proporção de candidatos eleitos: {:2.2%}\".format((num_elected_candidates/total_candidates)))\n",
    "print(\"Proporção de candidatos não-eleitos: {:2.2%}\".format((num_not_elected_candidates/total_candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável alvo **situacao** é bastante _desbalanceada_, em uma proporção de aproximadamente 1 eleito para cada 6 não-eleitos. Precisamente 13.46% dos candidatos foram eleitos, enquanto 86.54% não foram eleitos.\n",
    "\n",
    "Esse desbalanceamento pode causar alguns efeitos colaterais na classificação feita pelo modelo preditor, tais como overfitting do modelo em relação à classe majoritária, o que prejudica a acurácia da predição, podendo causar até mesmo a interpretação incorreta dos resultados se o desbalanceamento não for endereçado corretamente.\n",
    "\n",
    "Existem algumas práticas que podemos adotar para corrigir e lidar com esse desbalanceamento, a saber:\n",
    "\n",
    "* Coleta de mais dados, que poderia rebalancear as classes, a depender da natureza do problema;\n",
    "* Mudar a forma de amostragem do dataset, a qual pode estar gerando uma amostra desbalanceada, contudo o dataset não está desbalanceado;\n",
    "* Usar alguma forma de gerar dados sintéticos como Synthetic Minority Over-sampling Technique [SMOTE](https://imbalanced-learn.org/en/stable/over_sampling.html#cbhk2002) e Adaptive Synthetic [ADASYN](https://imbalanced-learn.org/en/stable/over_sampling.html#hbgl2008);\n",
    "* Incorporar algum modelo que tem uma forma de penalização para compensar o desbalanceamento de classes a exemplo de penalized-LDA e penalized-SVM.\n",
    "\n",
    "\n",
    "Para essa atividade nós usaremos a técnica de geração de dados sintéticos SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE: [(0.0, 6596), (1.0, 6596)]\n"
     ]
    }
   ],
   "source": [
    "train.drop(['situacao'], axis=1, inplace=True)\n",
    "\n",
    "X = train.loc[:, train.columns != 'situacao_dummy']\n",
    "y = train.situacao_dummy\n",
    "\n",
    "X_train, y_train = SMOTE().fit_resample(X, y)\n",
    "print(\"SMOTE: {}\".format(sorted(Counter(y_train).items())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (10553, 257)\n",
      "Test: (2639, 257)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train: {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Test: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_KNN (K-Nearest Neighbors)_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv_scores = []\n",
    "neighbors = range(3, 20, 2)\n",
    "neighbors = list(filter(lambda x: x % 2 != 0, neighbors))\n",
    "\n",
    "def run_classisier(k):\n",
    "    knr = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knr, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "cv_scores = Parallel(n_jobs=-1, verbose=1)(delayed(run_classisier)(k) for k in neighbors)\n",
    "   \n",
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print(\"The optimal number of neighbors is %d\" % optimal_k)\n",
    "\n",
    "# plot misclassification error vs k\n",
    "plt.plot(neighbors, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_cross_validation_results(model):\n",
    "    print('(Cross-)Validation set evaluation')\n",
    "    \n",
    "    report_val = {}\n",
    "    scoring = ['precision','recall','f1','accuracy', 'roc_auc']\n",
    "    for sc in scoring:\n",
    "        cv = StratifiedKFold(shuffle=True, random_state=42, n_splits=10)\n",
    "        report_val[sc] = cross_val_score(model, X_train, y_train, cv=cv, scoring=sc, n_jobs=-1).mean()\n",
    "    \n",
    "    for key, val in report_val.items():\n",
    "        print('{} score - validation set: {:.4}'.format(key.capitalize(), val))\n",
    "    \n",
    "    #print('Precision score - validation set: {0:0.2f}'.format(report_val['precision']))\n",
    "    #print('Recall score - validation set: {0:0.2f}'.format(report_val['recall']))\n",
    "    #print('F1 score - validation set: {0:0.2f}'.format(report_val['f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results_with_test_set(model):\n",
    "    print('----------------------')\n",
    "    print('Test set evaluation:')\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    report_test = {}\n",
    "    report_test['precision'] = precision_score(y_test, y_pred_test)\n",
    "    report_test['recall'] = recall_score(y_test, y_pred_test)\n",
    "    report_test['f1'] = f1_score(y_test, y_pred_test)\n",
    "    report_test['accuracy'] = accuracy_score(y_test, y_pred_test)\n",
    "    report_test['roc_auc'] = roc_auc_score(y_test, y_pred_test)\n",
    "    \n",
    "    for key, val in report_test.items():\n",
    "        print('{} score - test set: {:.4}'.format(key.capitalize(), val))\n",
    "\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Cross-)Validation set evaluation\n",
      "Precision score - validation set: 0.874\n",
      "Recall score - validation set: 0.9989\n",
      "F1 score - validation set: 0.9322\n",
      "Accuracy score - validation set: 0.9276\n",
      "Roc_auc score - validation set: 0.9573\n",
      "----------------------\n",
      "Test set evaluation:\n",
      "Precision score - test set: 0.8868\n",
      "Recall score - test set: 0.9985\n",
      "F1 score - test set: 0.9394\n",
      "Accuracy score - test set: 0.9344\n",
      "Roc_auc score - test set: 0.9333\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1126  171]\n",
      " [   2 1340]]\n"
     ]
    }
   ],
   "source": [
    "knr = KNeighborsClassifier(n_neighbors = 3).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(knr)\n",
    "report_results_with_test_set(knr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Logistic Regression_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Cross-)Validation set evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score - validation set: 0.9039\n",
      "Recall score - validation set: 0.9633\n",
      "F1 score - validation set: 0.9325\n",
      "Accuracy score - validation set: 0.9306\n",
      "Roc_auc score - validation set: 0.968\n",
      "----------------------\n",
      "Test set evaluation:\n",
      "Precision score - test set: 0.9069\n",
      "Recall score - test set: 0.9657\n",
      "F1 score - test set: 0.9354\n",
      "Accuracy score - test set: 0.9322\n",
      "Roc_auc score - test set: 0.9316\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1164  133]\n",
      " [  46 1296]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(lr)\n",
    "report_results_with_test_set(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _**Decision Tree Classifier**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Cross-)Validation set evaluation\n",
      "Precision score - validation set: 0.9295\n",
      "Recall score - validation set: 0.9458\n",
      "F1 score - validation set: 0.9375\n",
      "Accuracy score - validation set: 0.9372\n",
      "Roc_auc score - validation set: 0.9372\n",
      "----------------------\n",
      "Test set evaluation:\n",
      "Precision score - test set: 0.9278\n",
      "Recall score - test set: 0.9478\n",
      "F1 score - test set: 0.9377\n",
      "Accuracy score - test set: 0.936\n",
      "Roc_auc score - test set: 0.9358\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1198   99]\n",
      " [  70 1272]]\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state = 42).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(dt)\n",
    "report_results_with_test_set(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Adaboost Ensemble_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Cross-)Validation set evaluation\n",
      "Precision score - validation set: 0.8709\n",
      "Recall score - validation set: 0.9656\n",
      "F1 score - validation set: 0.9157\n",
      "Accuracy score - validation set: 0.9114\n",
      "Roc_auc score - validation set: 0.9242\n",
      "----------------------\n",
      "Test set evaluation:\n",
      "Precision score - test set: 0.8726\n",
      "Recall score - test set: 0.9642\n",
      "F1 score - test set: 0.9161\n",
      "Accuracy score - test set: 0.9102\n",
      "Roc_auc score - test set: 0.9093\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1108  189]\n",
      " [  48 1294]]\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(random_state=42, learning_rate=0.01).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(ada)\n",
    "report_results_with_test_set(ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Random Forest Classifier_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Cross-)Validation set evaluation\n",
      "Precision score - validation set: 0.9354\n",
      "Recall score - validation set: 0.9644\n",
      "F1 score - validation set: 0.9496\n",
      "Accuracy score - validation set: 0.949\n",
      "Roc_auc score - validation set: 0.9871\n",
      "----------------------\n",
      "Test set evaluation:\n",
      "Precision score - test set: 0.9359\n",
      "Recall score - test set: 0.968\n",
      "F1 score - test set: 0.9516\n",
      "Accuracy score - test set: 0.95\n",
      "Roc_auc score - test set: 0.9497\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1208   89]\n",
      " [  43 1299]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state = 42).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(rf)\n",
    "report_results_with_test_set(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Support Vector Classifier_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/ml-mestrado/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Cross-)Validation set evaluation\n",
      "Precision score - validation set: 0.8949\n",
      "Recall score - validation set: 0.9701\n",
      "F1 score - validation set: 0.9309\n",
      "Accuracy score - validation set: 0.9283\n",
      "Roc_auc score - validation set: 0.9708\n",
      "----------------------\n",
      "Test set evaluation:\n",
      "Precision score - test set: 0.8954\n",
      "Recall score - test set: 0.9762\n",
      "F1 score - test set: 0.934\n",
      "Accuracy score - test set: 0.9299\n",
      "Roc_auc score - test set: 0.9291\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1144  153]\n",
      " [  32 1310]]\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(svc)\n",
    "report_results_with_test_set(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Gradient Boosting Classifier_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Cross-)Validation set evaluation\n",
      "Precision score - validation set: 0.8787\n",
      "Recall score - validation set: 0.9753\n",
      "F1 score - validation set: 0.9244\n",
      "Accuracy score - validation set: 0.9205\n",
      "Roc_auc score - validation set: 0.9732\n",
      "----------------------\n",
      "Test set evaluation:\n",
      "Precision score - test set: 0.8823\n",
      "Recall score - test set: 0.9776\n",
      "F1 score - test set: 0.9275\n",
      "Accuracy score - test set: 0.9223\n",
      "Roc_auc score - test set: 0.9214\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1122  175]\n",
      " [  30 1312]]\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=42, learning_rate=0.01).fit(X_train, y_train)\n",
    "\n",
    "report_cross_validation_results(gbc)\n",
    "report_results_with_test_set(gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _**Logistic Regression-based Stacking Classifier**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_df = pd.DataFrame(columns=['lr','dt','ada','rf','svc','gbc','oracle'],\n",
    "                       data=[lr.predict(X_test),\n",
    "                             dl.predict(X_test),\n",
    "                             ada.predict(X_test),\n",
    "                             rf.predict(X_test),\n",
    "                             svc.predict(X_test),\n",
    "                             gbc.predict(X_test),\n",
    "                             y_test])\n",
    "stack_lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA - Usando Pipelines e GridSearch do Scikit Learn\n",
    "\n",
    "Abaixo nós fazemos alguns pipelines e grid searches com os mesmos algoritmos usados acima com o intuito de checar se os valores obtidos são correspondentes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def rmse_function(y_pred, y_true):\n",
    "    return np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
    "\n",
    "scorer = make_scorer(rmse_function, greater_is_better=False)\n",
    "\n",
    "# Construct some pipelines\n",
    "pipe_lr = Pipeline([('reg', LinearRegression())])\n",
    "pipe_rf = Pipeline([('reg', RandomForestRegressor())])\n",
    "pipe_lasso = Pipeline([('reg', LassoCV())])\n",
    "pipe_ridge = Pipeline([('reg', RidgeCV())])\n",
    "pipe_knn = Pipeline([('reg', KNeighborsRegressor())])\n",
    "pipe_dt = Pipeline([('reg', DecisionTreeRegressor())])\n",
    "pipe_svr = Pipeline([('reg', SVR())])\n",
    "\n",
    "\n",
    "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "grid_params_lr = [{}] \n",
    "\n",
    "grid_params_lasso = [{'reg__alphas' : [[5e-1, 1e-1, 5e-2, 1e-3, 1e-4, 1e-5, 1e-6]],\n",
    "                      'reg__max_iter' : [1e5],\n",
    "                      'reg__random_state' : [2]}]\n",
    "\n",
    "grid_params_ridge = [{'reg__alphas' : [[0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]]}]\n",
    "\n",
    "grid_params_rf = [{}]\n",
    "\n",
    "grid_params_knn = [{'reg__n_neighbors' : [1, 3, 5, 7, 10, 15, 18, 21]}]\n",
    "\n",
    "grid_params_dt = [{'reg__random_state' : [2],\n",
    "                   'reg__max_depth' : [5, 10, 50]}]\n",
    "\n",
    "grid_params_svr = [{'reg__C': [1e0, 1e1, 1e2, 1e3]}]\n",
    "\n",
    "# Construct grid searches\n",
    "jobs = -1\n",
    "\n",
    "gs_lr = GridSearchCV(estimator = pipe_lr,\n",
    "                param_grid = grid_params_lr,\n",
    "                scoring = scorer,\n",
    "                cv = 5) \n",
    "\n",
    "gs_rf = GridSearchCV(estimator = pipe_rf,\n",
    "                param_grid = grid_params_rf,\n",
    "                scoring = scorer,\n",
    "                cv = 5, \n",
    "                n_jobs = jobs)\n",
    "\n",
    "gs_lasso = GridSearchCV(estimator = pipe_lasso,\n",
    "                       param_grid = grid_params_lasso,\n",
    "                       scoring = scorer,\n",
    "                       cv = 5,\n",
    "                       n_jobs = jobs)\n",
    "\n",
    "gs_ridge = GridSearchCV(estimator = pipe_ridge,\n",
    "                       param_grid = grid_params_ridge,\n",
    "                       scoring = scorer,\n",
    "                       cv = 5,\n",
    "                       n_jobs = jobs)\n",
    "\n",
    "gs_knn = GridSearchCV(estimator = pipe_knn,\n",
    "                     param_grid = grid_params_knn,\n",
    "                     scoring = scorer,\n",
    "                     cv = 5,\n",
    "                     n_jobs = jobs)\n",
    "\n",
    "gs_dt = GridSearchCV(estimator = pipe_dt,\n",
    "                    param_grid = grid_params_dt,\n",
    "                    scoring = scorer,\n",
    "                    cv = 5,\n",
    "                    n_jobs = jobs)\n",
    "\n",
    "gs_svr = GridSearchCV(estimator = pipe_svr,\n",
    "                     param_grid = grid_params_svr,\n",
    "                     scoring = scorer,\n",
    "                     cv = 5,\n",
    "                     n_jobs = jobs)\n",
    "\n",
    "# List of pipelines for ease of iteration\n",
    "grids = [gs_lr, gs_rf, gs_ridge, gs_lasso, gs_knn, gs_dt, gs_svr]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "grid_dict = {0: 'Linear Regressor', 1: 'Random Forest Regressor', \n",
    "            2: 'Ridge Regressor', 3: 'Lasso Regressor', \n",
    "            4: 'KNN Regressor', 5: 'Decision Tree Regressor',\n",
    "            6: 'SVR Regressor'}\n",
    "\n",
    "\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_rmse = float(\"inf\")\n",
    "best_reg = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\n",
    "    # Fit grid search\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    \n",
    "    # Best training data accuracy\n",
    "    print('Best RMSE for training set: %.10f' % -gs.best_score_)\n",
    "    \n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_pred))\n",
    "    \n",
    "    # Validation data accuracy of model with best params\n",
    "    print('Test set RMSE for best params: %.10f ' % rmse)\n",
    "    \n",
    "    # Track best (smallest rmse) model\n",
    "    if best_rmse > rmse:\n",
    "        best_rmse = rmse\n",
    "        best_gs = gs\n",
    "        best_reg = idx\n",
    "        \n",
    "print('\\nRegressor with best test set RMSE: ** %s **' % grid_dict[best_reg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "Como se observa acima, o melhor modelo encontrado foi o modelo **Lasso Regressor** em termos de RMSE, com o modelo **Ridge Regressor** bem próximo dele em termos de RMSE.\n",
    "\n",
    "Entretanto os valores de RMSE são distintos dos valores encontrados acima. Isso pode se dever ao ajuste dos parâmetros dos modelos, feitos durante a própria busca, e/ou por alguma diferença na função de scoring, que talvez tenha passado despercebida pela nossa análise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
