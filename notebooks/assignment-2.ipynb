{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descrição\n",
    "\n",
    "Nessa tarefa você vai estender sua implementação da tarefa passada para considerar múltiplas variáveis. Você pode estender a versão vetorizada implementada neste notebook para regressão simples. \n",
    "\n",
    "- Rode o algoritmo nesses dados, onde as linhas representam as notas de alunos de computação de alunos da UFCG em algumas disciplinas do primeiro período. A última coluna é a variável alvo representando o CRA final depois de concluir o curso. As outras colunas são algumas disciplinas do primeiro período. O pressuposto aqui é que as notas em disciplinas no primeiro período ajudam a explicar o CRA final dos alunos de computação.\n",
    "\n",
    "- Compare o valor dos coeficientes estimados pelo seu algoritmo com o valor dos coeficientes da regressão linear do scikit learn para testar se o seu algoritmo está funcionando corretamente.\n",
    "\n",
    "A entrega deve ser o link no seu github para o notebook Jupyter com código python e texto explicativo quando necessário. De preferência, crie um repositório na sua conta do github e envie o link do html do notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Calc1</th>\n",
       "      <th>LPT</th>\n",
       "      <th>P1</th>\n",
       "      <th>IC</th>\n",
       "      <th>Calc2</th>\n",
       "      <th>cra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.477647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.851724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.090588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.283516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.205747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Calc1   LPT   P1   IC  Calc2       cra\n",
       "0    8.7  10.0  9.0  9.1    8.4  8.477647\n",
       "1    7.0   7.0  7.7  7.0    6.2  6.851724\n",
       "2    8.6   9.8  7.9  9.6    8.7  9.090588\n",
       "3    7.8   8.3  6.8  8.2    8.0  7.283516\n",
       "4    5.2   9.3  5.0  8.5    5.0  7.205747"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_df = pd.read_csv('../data/grades.csv')\n",
    "grades_df.rename(index=str, columns={'Cálculo1': 'Calc1', 'Cálculo2': 'Calc2'}, inplace=True)\n",
    "grades_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions\n",
    "\n",
    "### Compute Mean Squared Error - Vectorized Version\n",
    "\n",
    "$MSE(\\hat{w})=\\frac{1}{N}(y-\\hat{\\mathbf{w}}^T\\mathbf{x})^T(y-\\hat{\\mathbf{w}}^T\\mathbf{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_vectorized(w, X, Y):\n",
    "    res = Y - np.dot(X,w)\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError / float(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient_vectorized(w_current, X, Y, learningRate, itera, verbose=False, period=1000):\n",
    "    res = Y - np.dot(X,w_current)\n",
    "    b_gradient = np.sum(res)\n",
    "    X = X[:,1][:,np.newaxis]\n",
    "    m_gradient = np.sum(np.multiply(res,X))\n",
    "    new_w = np.array([(w_current[0] + (2 * learningRate * b_gradient)),\n",
    "             (w_current[1] + (2 * learningRate * m_gradient))])\n",
    "    \n",
    "    new_error = compute_mse_vectorized(new_w, X, Y)\n",
    "    l2_norm = np.linalg.norm([b_gradient, m_gradient], ord=2)  # compute l2-norm\n",
    "    \n",
    "    if verbose:\n",
    "        if itera % period == 0:\n",
    "            print(\"Step gradient at b = {0}, m = {1}, error = {2}, l2_norm = {3}\".format(new_b, new_m, new_error, l2_norm))\n",
    "    \n",
    "    return [new_w,b_gradient,m_gradient, new_error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_runner_vectorized(starting_w, X,Y, learning_rate, epsilon):\n",
    "    w = starting_w\n",
    "    grad = np.array([np.inf,np.inf])\n",
    "    i = 0\n",
    "    while (np.linalg.norm(grad)>=epsilon):\n",
    "        w,b_gradient,m_gradient = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "        grad = np.array([b_gradient,m_gradient])\n",
    "        #print(np.linalg.norm(grad))\n",
    "        if i % 1000 == 0:\n",
    "            print(\"MSE na iteração {0} é de {1}\".format(i,compute_mse_vectorized(w, X, Y)))\n",
    "        i+= 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def step_gradient(b_current, m_current, points, learningRate, itera, verbose=False, period=1000):\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        b_gradient += -(2/N) * (y - ((m_current * x) + b_current))\n",
    "        m_gradient += -(2/N) * x * (y - ((m_current * x) + b_current))\n",
    "    new_b = b_current - (learningRate * b_gradient)\n",
    "    new_m = m_current - (learningRate * m_gradient)\n",
    "    \n",
    "    new_error = compute_error_for_line_given_points(new_b, new_m, points)\n",
    "    l2_norm = np.linalg.norm([b_gradient, m_gradient], ord=2)  # compute l2-norm\n",
    "    \n",
    "    if verbose:\n",
    "        if itera % period == 0:\n",
    "            print(\"Step gradient at b = {0}, m = {1}, error = {2}, l2_norm = {3}\".format(new_b, new_m, new_error, l2_norm))\n",
    "       \n",
    "    return [new_b, new_m, b_gradient, m_gradient, new_error]\n",
    "\n",
    "def gradient_descent_runner(points, starting_b, starting_m, learning_rate, num_iterations):\n",
    "    b = starting_b\n",
    "    m = starting_m\n",
    "    history = pd.DataFrame(columns=['bias','slope','bias_grad', 'slope_grad','error','iter'])\n",
    "    iteration = 0\n",
    "    boundary = 1e-3\n",
    "    l2_norm = float(\"inf\")\n",
    "    while(l2_norm >= boundary):\n",
    "        step_grad = step_gradient(b, m, np.array(points), learning_rate, iteration, True)\n",
    "        b, m, b_gradient, m_gradient = step_grad[0], step_grad[1], step_grad[2], step_grad[3]\n",
    "        history = history.append({'bias': step_grad[0], 'slope': step_grad[1], 'bias_grad': step_grad[2],\n",
    "                        'slope_grad': step_grad[3], 'error': step_grad[4], 'iter': iteration}, ignore_index=True)\n",
    "        l2_norm = np.linalg.norm([b_gradient, m_gradient], ord=2)\n",
    "        iteration += 1\n",
    "        \n",
    "    return history\n",
    "\n",
    "def run():\n",
    "    points = np.genfromtxt(\"../data/income.csv\", delimiter=\",\")\n",
    "    learning_rate = 3 * 1e-3\n",
    "    initial_b = 0 # initial y-intercept guess\n",
    "    initial_m = 0 # initial slope guess\n",
    "    num_iterations = 20000\n",
    "    \n",
    "    initial_error = compute_error_for_line_given_points(initial_b, initial_m, points)\n",
    "    print(\"Starting gradient descent at b = {0}, m = {1}, error = {2}\".format(initial_b, initial_m, initial_error))\n",
    "    print(\"Running...\")\n",
    "    \n",
    "    history = gradient_descent_runner(points, initial_b, initial_m, learning_rate, num_iterations)\n",
    "    \n",
    "    final_bias = history['bias'][history.shape[0]-1]\n",
    "    final_slope = history['slope'][history.shape[0]-1]\n",
    "    final_error = compute_error_for_line_given_points(final_bias, final_slope, points)\n",
    "    num_iterations_need = history['iter'][history.shape[0]-1]\n",
    "    \n",
    "    print(\"After {0} iterations b = {1}, m = {2}, error = {3}\".format(num_iterations_need, final_bias, final_slope, final_error))\n",
    "    print(\"Learning Rate = {}\".format(learning_rate))\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_model(hist):\n",
    "    predictions_df = pd.DataFrame(df)\n",
    "    predictions_df = predictions_df.rename(index=str, columns={0 : 'Year', 1: 'Income'})\n",
    "    predictions_df.insert(loc=2, column='Predicted_Income', value=0.0)\n",
    "    \n",
    "    final_model = [hist['bias'][hist.shape[0]-1], hist['slope'][hist.shape[0]-1]]\n",
    "    model_slope = final_model[1]\n",
    "    model_bias = final_model[0]\n",
    "\n",
    "    for i in range(0, predictions_df.shape[0]):\n",
    "        year = predictions_df['Year'][i]\n",
    "        predictions_df['Predicted_Income'][i] = '{:2.6f}'.format(year * model_slope + model_bias)\n",
    "\n",
    "    plt.plot(predictions_df['Year'], predictions_df['Income'], 'bo', label='Original Data') \n",
    "    plt.plot(predictions_df['Year'], predictions_df['Predicted_Income'], 'r', label='Predicted Model') \n",
    "    plt.title('Comparison of Original Income and Predicted Income') \n",
    "    plt.xlabel('Years of Study')\n",
    "    plt.ylabel('Income in US$ 1000.00')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_error_on_training(hist):\n",
    "    plt.plot(hist['iter'], hist['error'] , 'r', label='Model Error') \n",
    "    plt.title('Model Error (RSS) By Iteration') \n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gradient_on_training(hist):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    ax.scatter(hist['iter'], \n",
    "               hist['bias_grad'], \n",
    "               hist['slope_grad'])\n",
    "    ax.set_ylabel('Bias Gradient')\n",
    "    ax.set_zlabel('Slope Gradient')\n",
    "    ax.set_xlabel('Iter')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_item_5 = run()\n",
    "\n",
    "plot_model_error_on_training(hist_item_5)\n",
    "plot_predicted_model(hist_item_5)\n",
    "plot_gradient_on_training(hist_item_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
